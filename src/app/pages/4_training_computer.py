"""
üöÄ ML FACTORY PRO - Training Computer Vision 
Architecture propre avec s√©paration UI/logique m√©tier
Support supervis√© + non-supervis√© unifi√©
"""

import streamlit as st
import numpy as np
import torch
import time
import plotly.graph_objects as go
from typing import Dict, Any, List
from collections import Counter

from src.shared.logging import get_logger

# === IMPORTS COMPOSANTS UI ===
from monitoring.state_managers import init, AppPage, STATE
from ui.training_vision import (
    inject_training_vision_css,
    detect_training_mode,
    perform_stratified_split,
    validate_split_quality,
    render_mode_badge,
    render_split_distribution_chart,
    render_split_stats_table,
    render_validation_warnings,
    filter_models_by_mode,
    analyze_imbalance_by_mode,
    render_imbalance_analysis
)

# === IMPORTS LOGIQUE M√âTIER ===
from src.models.computer_vision_training import (
    TrainingConfig,
    ModelType,
    OptimizerType,
    SchedulerType,
    DataAugmenter,
)
from orchestrators.visio_training_orchestrator import (
    training_orchestrator,
    TrainingContext
)
from utils.callbacks import LoggingCallback, StreamlitCallback
from sklearn.utils.class_weight import compute_class_weight

logger = get_logger(__name__)

# Configuration Streamlit
st.set_page_config(
    page_title="ML Factory Pro | Training CV",
    page_icon="üöÄ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Initialisation STATE
init()


class MLTrainingWorkflowPro:
    """
    Workflow professionnel refactoris√©
    Support complet supervis√© + non-supervis√©
    """
    
    def __init__(self):
        self.logger = logger
        inject_training_vision_css()
    
    def render_header(self):
        """Header avec d√©tection mode automatique"""
        col1, col2, col3 = st.columns([2, 1, 1])
        
        with col1:
            st.markdown('<div class="main-header">üöÄ ML Factory Pro</div>', unsafe_allow_html=True)
            st.markdown("**Workflow Intelligent Computer Vision**")
        
        with col2:
            st.metric("√âtape", f"{STATE.current_step + 1}/6")
            
        with col3:
            device = "CUDA üöÄ" if torch.cuda.is_available() else "CPU ‚ö°"
            st.caption(f"Device: {device}")
            
            # Affichage mode si d√©tect√©
            if STATE.loaded and STATE.data.y is not None:
                mode, _ = detect_training_mode(STATE.data.y)
                badge_color = "#4facfe" if mode == "supervised" else "#f5576c"
                st.markdown(
                    f"<div style='background:{badge_color};color:white;padding:0.3rem;border-radius:5px;text-align:center;font-size:0.7rem;'>"
                    f"{'üéØ SUPERVIS√â' if mode == 'supervised' else 'üîç ANOMALIES'}"
                    f"</div>",
                    unsafe_allow_html=True
                )
    
    def render_workflow_progress(self):
        """Barre progression"""
        steps = [
            ("üìä", "Donn√©es", "Split et Analyse"),
            ("‚öñÔ∏è", "D√©s√©quilibre", "Analyse et Correction"),
            ("üé®", "Pr√©traitement", "Normalisation"),
            ("ü§ñ", "Mod√®le", "Architecture"),
            ("‚öôÔ∏è", "Entra√Ænement", "Hyperparam√®tres"),
            ("üöÄ", "Lancement", "Monitoring")
        ]
        
        st.markdown("### üìã Progression du Workflow")
        
        cols = st.columns(len(steps))
        for idx, (col, (icon, name, desc)) in enumerate(zip(cols, steps)):
            with col:
                if idx < STATE.current_step:
                    status = ("‚úÖ", "#28a745", "Termin√©")
                elif idx == STATE.current_step:
                    status = ("üîµ", "#667eea", "En cours")
                else:
                    status = ("‚ö™", "#6c757d", "√Ä venir")
                
                st.markdown(
                    f"""<div style="text-align:center;padding:1rem;border-radius:10px;
                    background:{'#f8f9ff' if idx == STATE.current_step else 'white'};
                    border:2px solid {status[1]};">
                    <div style="font-size:1.5rem;margin-bottom:0.5rem;">{icon}</div>
                    <div style="font-weight:bold;color:{status[1]};">{name}</div>
                    <div style="font-size:0.8rem;color:#666;">{desc}</div>
                    <div style="font-size:0.7rem;color:{status[1]};margin-top:0.5rem;">
                    {status[0]} {status[2]}</div></div>""",
                    unsafe_allow_html=True
                )
        
        st.markdown("---")
    
    # ========================================================================
    # √âTAPE 1: SPLIT AVEC D√âTECTION MODE
    # ========================================================================
    
    def render_data_analysis_step(self):
        """√âtape 1 refactoris√©e avec d√©tection mode"""
        st.markdown('<div class="workflow-step-card">', unsafe_allow_html=True)
        st.header("üìä √âtape 1: Analyse et Split des Donn√©es")
        
        # V√©rification chargement
        if not STATE.loaded or STATE.data.X is None:
            st.error("‚ùå Aucun dataset charg√©")
            st.info("Chargez un dataset depuis le dashboard")
            if st.button("üìä Dashboard", type="primary"):
                st.switch_page("pages/1_dashboard.py")
            st.markdown('</div>', unsafe_allow_html=True)
            return
        
        X, y = STATE.data.X, STATE.data.y
        
        # === D√âTECTION AUTOMATIQUE DU MODE ===
        try:
            if hasattr(STATE.data, 'y_train') and STATE.data.y_train is not None:
                mode, metadata = detect_training_mode(STATE.data.y_train)
            else:
                # Fallback si pas encore splitt√©
                mode, metadata = detect_training_mode(STATE.data.y)
            
            logger.info(f"Mode d√©tect√©: {mode} | Metadata: {metadata}")
        except ValueError as e:
            st.error(f"‚ùå {e}")
            st.markdown('</div>', unsafe_allow_html=True)
            return
        
        # Badge mode
        col_mode1, col_mode2 = st.columns([1, 2])
        with col_mode1:
            render_mode_badge(mode, metadata)
        
        with col_mode2:
            st.info(f"""
            **Caract√©ristiques D√©tect√©es:**
            - **Images totales:** {len(X):,}
            - **Classes:** {metadata['n_classes']}
            - **T√¢che:** {metadata['task'].replace('_', ' ').title()}
            """)
        
        st.markdown("---")
        
        # === CONFIGURATION SPLIT ===
        st.subheader("üîß Configuration du Split")
        
        col1, col2 = st.columns(2)
        with col1:
            test_size = st.slider(
                "Taille Test Set (%)",
                10, 40, 20, 5,
                help="Pourcentage r√©serv√© au test final"
            )
        
        with col2:
            val_size = st.slider(
                "Taille Validation Set (%)",
                10, 30, 20, 5,
                help="Pourcentage du train_val pour validation"
            )
        
        # Calcul tailles
        test_ratio = test_size / 100
        val_ratio = val_size / 100
        
        n_test = int(len(X) * test_ratio)
        n_train_val = len(X) - n_test
        n_val = int(n_train_val * val_ratio)
        n_train = n_train_val - n_val
        
        # M√©triques
        col_met1, col_met2, col_met3 = st.columns(3)
        with col_met1:
            st.metric("üèãÔ∏è Training", f"{n_train:,}")
        with col_met2:
            st.metric("üìä Validation", f"{n_val:,}")
        with col_met3:
            st.metric("üß™ Test", f"{n_test:,}")
        
        # === BOUTON SPLIT ===
        st.markdown("---")
        if st.button("üîÑ Effectuer le Split", type="primary", use_container_width=True):
            with st.spinner("Split en cours..."):
                try:
                    # Split avec fonction helper
                    split_result = perform_stratified_split(
                        X, y,
                        test_size=test_ratio,
                        val_size=val_ratio,
                        mode=mode
                    )
                    
                    # Validation
                    is_valid, warnings = validate_split_quality(split_result, mode, metadata)
                    
                    if not is_valid:
                        st.error("‚ùå Split invalide")
                        render_validation_warnings(warnings)
                        st.markdown('</div>', unsafe_allow_html=True)
                        return
                    
                    # Sauvegarde STATE
                    STATE.data.X_train = split_result["X_train"]
                    STATE.data.X_val = split_result["X_val"]
                    STATE.data.X_test = split_result["X_test"]
                    STATE.data.y_train = split_result["y_train"]
                    STATE.data.y_val = split_result["y_val"]
                    STATE.data.y_test = split_result["y_test"]
                    
                    STATE.data.split_config = split_result["split_info"]
                    STATE.data.split_config["mode"] = mode
                    STATE.data.split_config["metadata"] = metadata
                    
                    # Visualisation
                    st.success("‚úÖ Split effectu√© avec succ√®s")
                    render_split_distribution_chart(split_result, mode)
                    render_split_stats_table(split_result, mode, metadata)
                    render_validation_warnings(warnings)
                    
                    st.balloons()
                    STATE.current_step = 1
                    st.rerun()
                
                except Exception as e:
                    logger.error(f"Erreur split: {e}", exc_info=True)
                    st.error(f"‚ùå Erreur: {e}")
        
        st.markdown('</div>', unsafe_allow_html=True)
    
    # ========================================================================
    # √âTAPE 2: D√âS√âQUILIBRE ADAPTATIF
    # ========================================================================
    
    def render_imbalance_analysis_step(self):
        """√âtape 2 refactoris√©e avec logique par mode"""
        st.markdown('<div class="workflow-step-card">', unsafe_allow_html=True)
        st.header("‚öñÔ∏è √âtape 2: Gestion du D√©s√©quilibre")
        
        if not STATE.loaded or STATE.data.y_train is None:
            st.error("‚ùå Donn√©es d'entra√Ænement manquantes")
            if st.button("‚¨ÖÔ∏è Retour √âtape 1"):
                STATE.current_step = 0
                st.rerun()
            st.markdown('</div>', unsafe_allow_html=True)
            return
        
        y_train = STATE.data.y_train
        
        # R√©cup√©ration mode
        split_config = getattr(STATE.data, 'split_config', {})
        mode = split_config.get('mode', 'supervised')
        metadata = split_config.get('metadata', {})
        
        # Badge rappel mode
        render_mode_badge(mode, metadata)
        st.markdown("---")
        
        # === ANALYSE D√âS√âQUILIBRE ===
        imbalance_info = analyze_imbalance_by_mode(y_train, mode, metadata)
        
        render_imbalance_analysis(imbalance_info, y_train)
        
        st.markdown("---")
        
        # === OPTIONS CORRECTION (CONDITIONNELLES) ===
        st.subheader("üéØ Strat√©gies de Correction")
        
        if mode == "supervised":
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("#### ‚öñÔ∏è Poids de Classe")
                use_weights = st.checkbox(
                    "Activer poids automatiques",
                    value=imbalance_info["use_class_weights"],
                    help="Ajuste loss function selon d√©s√©quilibre"
                )
                
                if use_weights:
                    classes = np.unique(y_train)
                    weights = compute_class_weight('balanced', classes=classes, y=y_train)
                    weight_dict = {int(cls): float(weight) for cls, weight in zip(classes, weights)}
                    
                    st.info("**Poids calcul√©s:**")
                    for cls, weight in weight_dict.items():
                        st.write(f"- Classe {cls}: `{weight:.3f}`")
                    
                    STATE.class_weights = weight_dict
            
            with col2:
                st.markdown("#### üé≠ SMOTE")
                use_smote = st.checkbox(
                    "Activer SMOTE",
                    value=imbalance_info["use_smote"],
                    disabled=not imbalance_info["use_smote"],
                    help="G√©n√®re √©chantillons synth√©tiques classes minoritaires"
                )
        
        else:  # unsupervised
            st.info("""
            **‚ÑπÔ∏è Mode D√©tection d'Anomalies**
            
            Les autoencoders apprennent √† reconstruire uniquement les images **normales**.
            Le d√©s√©quilibre normal/anomalie est **attendu et souhait√©**.
            
            ‚ö†Ô∏è **Class weights d√©sactiv√©s** (contre-productif pour autoencoders)
            """)
            use_weights = False
            use_smote = False
        
        # Navigation
        st.markdown("---")
        col_nav1, col_nav2 = st.columns(2)
        
        with col_nav1:
            if st.button("‚¨ÖÔ∏è Retour"):
                STATE.current_step = 0
                st.rerun()
        
        with col_nav2:
            if st.button("üíæ Continuer ‚û°Ô∏è", type="primary"):
                # Sauvegarde config
                STATE.imbalance_config = {
                    "use_class_weights": use_weights,
                    "use_smote": use_smote,
                    "imbalance_ratio": float(imbalance_info["ratio"]),
                    "mode": mode,
                    "metadata": metadata
                }
                
                # Propager aux configs training si n√©cessaire
                if not hasattr(STATE, 'training_config') or STATE.training_config is None:
                    STATE.training_config = {}
                
                if isinstance(STATE.training_config, dict):
                    STATE.training_config['use_class_weights'] = use_weights
                
                st.success("‚úÖ Configuration sauvegard√©e")
                STATE.current_step = 2
                st.rerun()
        
        st.markdown('</div>', unsafe_allow_html=True)
    
    # ========================================================================
    # √âTAPE 3: PR√âTRAITEMENT
    # ========================================================================
    
    def render_preprocessing_step(self):
        """√âtape 3 - Pr√©traitement"""
        st.markdown('<div class="workflow-step-card">', unsafe_allow_html=True)
        st.header("üé® √âtape 3: Pr√©traitement des Images")
        
        split_config = getattr(STATE.data, 'split_config', {})
        mode = split_config.get('mode', 'supervised')
        
        st.markdown("**Configuration du pipeline de pr√©traitement**")
        
        # Normalisation
        st.subheader("üîß Normalisation")
        
        col1, col2 = st.columns(2)
        
        with col1:
            normalization = st.selectbox(
                "M√©thode",
                ["standardize", "normalize", "none"],
                index=0,
                help="standardize: (x-mean)/std | normalize: [0,1] | none: aucune"
            )
        
        with col2:
            # AFFICHAGE taille actuelle
            if STATE.data.X is not None:
                sample_shape = STATE.data.X.shape
                
                # D√©tection format
                if sample_shape[-1] in [1, 3, 4]:  # channels_last
                    current_h, current_w = sample_shape[1], sample_shape[2]
                else:  # channels_first
                    current_h, current_w = sample_shape[2], sample_shape[3]
                
                st.info(f"üìè Taille actuelle: {current_h}√ó{current_w}")
            
            # Parser correctement le resize
            resize_options = ["Conserver", "128√ó128", "224√ó224", "256√ó256"]
            resize_choice = st.selectbox(
                "Redimensionnement",
                resize_options,
                index=0,
                help="Redimensionner toutes les images √† une taille fixe"
            )
        
        st.markdown("---")
        
        # Augmentation
        st.subheader("üé≠ Augmentation de Donn√©es")
        
        if not hasattr(STATE, 'preprocessing_config') or STATE.preprocessing_config is None:
            STATE.preprocessing_config = {}
        
        augmentation_enabled = st.checkbox(
            "Activer augmentation",
            value=STATE.preprocessing_config.get("augmentation_enabled", False)
        )
        
        methods = []
        augmentation_factor = 1
        
        if augmentation_enabled:
            col_aug1, col_aug2 = st.columns(2)
            
            with col_aug1:
                augmentation_factor = st.slider(
                    "Facteur multiplication",
                    1, 5,
                    STATE.preprocessing_config.get("augmentation_factor", 2)
                )
            
            with col_aug2:
                st.markdown("**Techniques:**")
                if st.checkbox("Flip horizontal", value=True):
                    methods.append('flip')
                if st.checkbox("Rotation ¬±15¬∞", value=True):
                    methods.append('rotate')
                if st.checkbox("Zoom al√©atoire", value=False):
                    methods.append('zoom')
                if st.checkbox("Luminosit√©", value=False):
                    methods.append('brightness')
            
            # Warning si mode anomalie
            if mode == "unsupervised":
                st.warning("‚ö†Ô∏è Mode anomalies: augmentation appliqu√©e uniquement sur images normales")
        
        # Navigation
        st.markdown("---")
        col_nav1, col_nav2 = st.columns(2)
        
        with col_nav1:
            if st.button("‚¨ÖÔ∏è Retour"):
                STATE.current_step = 1
                st.rerun()
        
        with col_nav2:
            if st.button("üíæ Continuer ‚û°Ô∏è", type="primary"):

                # Sauvegarde config
                target_size = None
                if resize_choice != "Conserver":

                    # Extraction "224√ó224" ‚Üí (224, 224)
                    size_str = resize_choice.replace("√ó", "x")  # Normalisation
                    try:
                        h_str, w_str = size_str.split("x")
                        target_size = (int(h_str), int(w_str))
                        logger.info(f"‚úÖ Resize activ√©: target_size={target_size}")
                    except Exception as e:
                        logger.error(f"‚ùå Erreur parsing resize '{resize_choice}': {e}")
                        st.error(f"Format resize invalide: {resize_choice}")
                        return
                
                # SAUVEGARDE avec target_size
                STATE.preprocessing_config = {
                    "strategy": normalization,
                    "target_size": target_size,  
                    "augmentation_enabled": augmentation_enabled,
                    "augmentation_factor": augmentation_factor,
                    "methods": methods
                }
                
                st.success("‚úÖ Configuration sauvegard√©e")
                STATE.current_step = 3
                st.rerun()
        
        st.markdown('</div>', unsafe_allow_html=True)
    
    # ========================================================================
    # √âTAPE 4: S√âLECTION MOD√àLE AVEC FILTRAGE
    # ========================================================================
    
    def render_model_selection_step(self):
        """√âtape 4 avec filtrage mod√®les par mode"""
        st.markdown('<div class="workflow-step-card">', unsafe_allow_html=True)
        st.header("ü§ñ √âtape 4: S√©lection du Mod√®le")
        
        # R√©cup√©ration mode
        split_config = getattr(STATE.data, 'split_config', {})
        mode = split_config.get('mode', 'supervised')
        metadata = split_config.get('metadata', {})
        
        # Rappel mode
        col_mode, _ = st.columns([1, 2])
        with col_mode:
            render_mode_badge(mode, metadata)
        
        st.markdown("---")
        
        # Catalogue complet
        all_models = self.get_model_categories()
        
        # === FILTRAGE PAR MODE ===
        available_models = filter_models_by_mode(all_models, mode, metadata)
        
        if not available_models:
            st.error(f"‚ùå Aucun mod√®le compatible avec mode {mode}")
            st.markdown('</div>', unsafe_allow_html=True)
            return
        
        n_models = sum(len(cat['models']) for cat in available_models.values())
        st.info(f"**{n_models} mod√®les** disponibles pour mode **{mode}**")
        
        st.markdown("### üéØ Mod√®les Disponibles")
        
        # Affichage par cat√©gorie
        for category, category_data in available_models.items():
            with st.expander(f"{category} ({len(category_data['models'])} mod√®les)", expanded=True):
                st.markdown(f"*{category_data['description']}*")
                
                # Grille 2 colonnes
                model_cols = st.columns(2)
                
                for idx, model in enumerate(category_data["models"]):
                    col = model_cols[idx % 2]
                    
                    with col:
                        is_selected = STATE.selected_model_type == model["id"]
                        
                        card_class = "model-card selected" if is_selected else "model-card"
                        
                        st.markdown(
                            f"""<div class="{card_class}">
                            <div style="display:flex;align-items:start;margin-bottom:1rem;">
                                <span style="font-size:2rem;margin-right:1rem;">{model['icon']}</span>
                                <div style="flex:1;">
                                    <h4 style="margin:0 0 0.5rem 0;">{model['name']}</h4>
                                    <span class="status-badge badge-info">{model['complexity']}</span>
                                </div>
                            </div>
                            <p style="color:#666;font-size:0.9rem;">{model['description']}</p>
                            </div>""",
                            unsafe_allow_html=True
                        )
                        
                        if st.button(
                            "‚úÖ S√©lectionn√©" if is_selected else "üìù S√©lectionner",
                            key=f"select_{model['id']}",
                            use_container_width=True,
                            type="primary" if is_selected else "secondary"
                        ):
                            STATE.selected_model_type = model["id"]
                            STATE.model_config = {
                                "model_type": model["id"],
                                "model_params": self.get_default_model_params(model["id"])
                            }
                            st.success(f"‚úÖ {model['name']} s√©lectionn√©")
                            st.rerun()
        
        # Config avanc√©e si mod√®le s√©lectionn√©
        if STATE.selected_model_type:
            st.markdown("---")
            st.subheader(f"‚öôÔ∏è Configuration - {STATE.selected_model_type.upper()}")
            self.render_model_specific_parameters()
        
        # Navigation
        st.markdown("---")
        col_nav1, col_nav2 = st.columns(2)
        
        with col_nav1:
            if st.button("‚¨ÖÔ∏è Retour"):
                STATE.current_step = 2
                st.rerun()
        
        with col_nav2:
            if st.button("üíæ Continuer ‚û°Ô∏è", type="primary"):
                if STATE.selected_model_type:
                    STATE.current_step = 4
                    st.rerun()
                else:
                    st.error("‚ùå S√©lectionnez un mod√®le")
        
        st.markdown('</div>', unsafe_allow_html=True)
    
    def get_model_categories(self):
        """Catalogue complet des mod√®les"""
        return {
            "üéØ Classification Supervis√©e": {
                "color": "#28a745",
                "description": "Mod√®les pour classification avec labels",
                "models": [
                    {
                        "id": "simple_cnn",
                        "name": "CNN Simple",
                        "description": "R√©seau basique - Id√©al prototypage",
                        "icon": "üñºÔ∏è",
                        "complexity": "D√©butant"
                    },
                    {
                        "id": "custom_resnet",
                        "name": "ResNet Personnalis√©",
                        "description": "Architecture r√©siduelle profonde",
                        "icon": "üèóÔ∏è",
                        "complexity": "Interm√©diaire"
                    },
                    {
                        "id": "transfer_learning",
                        "name": "Transfer Learning",
                        "description": "Mod√®les pr√©-entra√Æn√©s ImageNet",
                        "icon": "üîÑ",
                        "complexity": "Avanc√©"
                    }
                ]
            },
            "üîç D√©tection d'Anomalies": {
                "color": "#dc3545",
                "description": "Mod√®les pour anomalies sans/avec peu labels",
                "models": [
                    {
                        "id": "conv_autoencoder",
                        "name": "AutoEncodeur Convolutif",
                        "description": "Reconstruit images normales",
                        "icon": "üé≠",
                        "complexity": "Interm√©diaire"
                    },
                    {
                        "id": "variational_autoencoder",
                        "name": "VAE (Variational)",
                        "description": "Mod√®le g√©n√©ratif probabiliste",
                        "icon": "üåå",
                        "complexity": "Avanc√©"
                    },
                    {
                        "id": "denoising_autoencoder",
                        "name": "AutoEncodeur Denoiseur",
                        "description": "Robuste au bruit",
                        "icon": "üßπ",
                        "complexity": "Interm√©diaire"
                    },
                    {
                        "id": "patch_core",
                        "name": "PatchCore",
                        "description": "State-of-the-art d√©fauts locaux",
                        "icon": "üß©",
                        "complexity": "Expert"
                    }
                ]
            }
        }
    
    def get_default_model_params(self, model_type: str):
        """Param√®tres par d√©faut"""
        defaults = {
            "simple_cnn": {
                "input_channels": 3,
                "num_classes": 2,
                "base_filters": 32,
                "dropout_rate": 0.5
            },
            "custom_resnet": {
                "input_channels": 3,
                "num_classes": 2,
                "base_filters": 64,
                "dropout_rate": 0.3
            },
            "transfer_learning": {
                "input_channels": 3,
                "num_classes": 2,
                "backbone_name": "resnet50",
                "pretrained": True,
                "dropout_rate": 0.5
            },
            "conv_autoencoder": {
                "input_channels": 3,
                "latent_dim": 256,
                "base_filters": 32,
                "num_stages": 4
            },
            "variational_autoencoder": {
                "input_channels": 3,
                "latent_dim": 128,
                "base_filters": 32,
                "beta": 1.0
            },
            "denoising_autoencoder": {
                "input_channels": 3,
                "latent_dim": 256,
                "noise_factor": 0.1
            },
            "patch_core": {
                "backbone_name": "wide_resnet50_2",
                "patchcore_layers": ["layer2", "layer3"],
                "coreset_ratio": 0.01
            }
        }
        
        return defaults.get(model_type, {"input_channels": 3})
    

    def render_model_specific_parameters(self):
        """Param√®tres sp√©cifiques au mod√®le avec UI compl√®te"""
        model_type = STATE.selected_model_type
        model_params = STATE.model_config.get("model_params", {})
        
        # === AUTOENCODERS: latent_dim + base_filters ===
        if model_type in ["conv_autoencoder", "variational_autoencoder", "denoising_autoencoder"]:
            st.markdown("#### üîß Configuration AutoEncoder")
            
            col1, col2 = st.columns(2)
            
            with col1:
                # SLIDER latent_dim
                latent_dim = st.slider(
                    "Dimension Espace Latent",
                    min_value=32,
                    max_value=1024,
                    value=model_params.get("latent_dim", 128),
                    step=32,
                    help=(
                        "Taille du bottleneck (compression maximale). "
                        "Plus petit = compression forte (risque underfitting). "
                        "Plus grand = moins de compression (risque overfitting)."
                    )
                )
                
                # Indicateur qualit√©
                if latent_dim < 64:
                    st.warning("‚ö†Ô∏è Tr√®s petit - Risque underfitting")
                elif latent_dim > 512:
                    st.info("‚ÑπÔ∏è Grande dimension - Moins de compression")
            
            with col2:
                base_filters = st.slider(
                    "Filtres de base",
                    16, 128,
                    model_params.get("base_filters", 32),
                    16,
                    help="Nombre de filtres du premier bloc (doubl√©s √† chaque stage)"
                )
            
            # CALCUL taux compression (si donn√©es charg√©es)
            if hasattr(STATE.data, 'X') and STATE.data.X is not None:
                sample_shape = STATE.data.X.shape
                
                # D√©tection format
                if sample_shape[-1] in [1, 3, 4]:  # channels_last
                    h, w, c = sample_shape[1], sample_shape[2], sample_shape[3]
                else:  # channels_first
                    c, h, w = sample_shape[1], sample_shape[2], sample_shape[3]
                
                input_pixels = h * w * c
                compression_ratio = input_pixels / latent_dim
                
                st.info(
                    f"üìä Taux compression: **{compression_ratio:.1f}:1** "
                    f"({input_pixels:,} pixels ‚Üí {latent_dim} dimensions latentes)"
                )
            
            # Mise √† jour STATE
            STATE.model_config["model_params"].update({
                "latent_dim": latent_dim,
                "base_filters": base_filters
            })
        
        # === CLASSIFICATION CNN ===
        elif model_type in ["simple_cnn", "custom_resnet"]:
            col1, col2 = st.columns(2)
            
            with col1:
                base_filters = st.slider(
                    "Filtres de base",
                    16, 128,
                    model_params.get("base_filters", 32),
                    16
                )
            
            with col2:
                dropout_rate = st.slider(
                    "Dropout",
                    0.0, 0.7,
                    model_params.get("dropout_rate", 0.5),
                    0.1
                )
            
            STATE.model_config["model_params"].update({
                "base_filters": base_filters,
                "dropout_rate": dropout_rate
            })
        
        # === TRANSFER LEARNING ===
        elif model_type == "transfer_learning":
            col1, col2 = st.columns(2)
            
            with col1:
                backbone = st.selectbox(
                    "Backbone",
                    ["resnet18", "resnet50", "efficientnet_b0", "mobilenet_v2"],
                    index=1
                )
            
            with col2:
                dropout_rate = st.slider("Dropout", 0.0, 0.7, 0.5, 0.1)
            
            STATE.model_config["model_params"].update({
                "backbone_name": backbone,
                "dropout_rate": dropout_rate
            })
    
    # ========================================================================
    # √âTAPE 5: CONFIGURATION ENTRA√éNEMENT
    # ========================================================================
    
    def render_training_config_step(self):
        """√âtape 5: Configuration des hyperparam√®tres d'entra√Ænement"""
        st.markdown('<div class="workflow-step-card">', unsafe_allow_html=True)
        st.header("‚öôÔ∏è √âtape 5: Configuration de l'Entra√Ænement")
        
        st.markdown("**Hyperparam√®tres d'entra√Ænement**")
        
        # Configuration de base
        col_hyper1, col_hyper2, col_hyper3 = st.columns(3)
        
        with col_hyper1:
            epochs = st.slider(
                "Nombre d'√âpoques",
                5, 200, 50, 5,
                help="Nombre de passages complets sur le dataset"
            )
        
        with col_hyper2:
            learning_rate = st.select_slider(
                "Learning Rate",
                options=[1e-5, 5e-5, 1e-4, 5e-4, 1e-3, 5e-3],
                value=1e-4,
                format_func=lambda x: f"{x:.0e}",
                help="Taux d'apprentissage"
            )
        
        with col_hyper3:
            batch_size = st.selectbox(
                "Batch Size",
                options=[8, 16, 32, 64, 128],
                index=2,
                help="Nombre d'images par batch"
            )
        
        st.markdown("---")
        
        # Optimiseur et Scheduler
        st.subheader("üéØ Optimiseur et Scheduler")
        
        col_opt1, col_opt2 = st.columns(2)
        
        with col_opt1:
            optimizer = st.selectbox(
                "Optimiseur",
                options=["adamw", "adam", "sgd", "rmsprop"],
                index=0,
                help="AdamW recommand√© pour la plupart des cas"
            )
        
        with col_opt2:
            scheduler = st.selectbox(
                "Scheduler",
                options=["reduce_on_plateau", "cosine", "step", "none"],
                index=0,
                help="ReduceLROnPlateau r√©duit automatiquement le LR"
            )
        
        st.markdown("---")
        
        # Early Stopping et R√©gularisation
        st.subheader("üõë Early Stopping & R√©gularisation")
        
        col_callback1, col_callback2, col_callback3 = st.columns(3)
        
        with col_callback1:
            early_stopping_patience = st.slider(
                "Early Stopping Patience",
                3, 30, 10,
                help="Arr√™te l'entra√Ænement si pas d'am√©lioration"
            )
        
        with col_callback2:
            reduce_lr_patience = st.slider(
                "Reduce LR Patience",
                2, 15, 5,
                help="R√©duit le LR si pas d'am√©lioration"
            )
        
        with col_callback3:
            weight_decay = st.select_slider(
                "Weight Decay",
                options=[0.0, 0.001, 0.01, 0.1],
                value=0.01,
                help="R√©gularisation L2"
            )
        
        # Options avanc√©es
        with st.expander("üîß Options Avanc√©es"):
            col_adv1, col_adv2 = st.columns(2)
            
            with col_adv1:
                gradient_clip = st.slider(
                    "Gradient Clipping",
                    0.0, 5.0, 1.0, 0.5,
                    help="Limite l'amplitude des gradients"
                )
                
                deterministic = st.checkbox(
                    "Mode D√©terministe",
                    value=True,
                    help="Rend les r√©sultats reproductibles"
                )
            
            with col_adv2:
                use_mixed_precision = st.checkbox(
                    "Mixed Precision (FP16)",
                    value=torch.cuda.is_available(),
                    disabled=not torch.cuda.is_available(),
                    help="Acc√©l√®re l'entra√Ænement sur GPU"
                )
                
                num_workers = st.slider(
                    "DataLoader Workers",
                    0, 8, 4,
                    help="Processus pour charger les donn√©es"
                )
        
        # Navigation
        st.markdown("---")
        col_nav1, col_nav2 = st.columns(2)
        
        with col_nav1:
            if st.button("‚¨ÖÔ∏è Retour"):
                STATE.current_step = 3
                st.rerun()
        
        with col_nav2:
            if st.button("üíæ Sauvegarder et Continuer ‚û°Ô∏è", type="primary"):
                # Cr√©ation de la configuration d'entra√Ænement
                STATE.training_config = {
                    "epochs": epochs,
                    "batch_size": batch_size,
                    "learning_rate": learning_rate,
                    "weight_decay": weight_decay,
                    "gradient_clip": gradient_clip,
                    "optimizer": optimizer,
                    "scheduler": scheduler,
                    "early_stopping_patience": early_stopping_patience,
                    "reduce_lr_patience": reduce_lr_patience,
                    "use_class_weights": STATE.imbalance_config.get('use_class_weights', False),
                    "deterministic": deterministic,
                    "use_mixed_precision": use_mixed_precision,
                    "num_workers": num_workers,
                    "seed": 42
                }
                
                st.success("‚úÖ Configuration d'entra√Ænement sauvegard√©e")
                STATE.current_step = 5
                st.rerun()
        
        st.markdown('</div>', unsafe_allow_html=True)
    
    # ========================================================================
    # √âTAPE 6: LANCEMENT ET MONITORING
    # ========================================================================
    
    def render_training_launch_step(self):
        """√âtape 6: Lancement de l'entra√Ænement"""
        st.markdown('<div class="workflow-step-card">', unsafe_allow_html=True)
        st.header("üöÄ √âtape 6: Lancement de l'Entra√Ænement")
        
        # R√©capitulatif de la configuration
        st.subheader("üìã R√©capitulatif de la Configuration")
        
        col_summary1, col_summary2 = st.columns(2)
        
        with col_summary1:
            st.subheader("üìä Donn√©es et Pr√©paration")
            
            split_config = getattr(STATE.data, 'split_config', None)
            if split_config:
                st.json(split_config)
            else:
                st.info("Aucune configuration de split disponible")
            
            st.subheader("‚öñÔ∏è Gestion du D√©s√©quilibre")
            if hasattr(STATE, 'imbalance_config') and STATE.imbalance_config:
                st.json(STATE.imbalance_config)
            else:
                st.info("Aucune configuration de d√©s√©quilibre disponible")
            
            st.subheader("üé® Pr√©traitement")
            if hasattr(STATE, 'preprocessing_config') and STATE.preprocessing_config:
                st.json(STATE.preprocessing_config)
            else:
                st.info("Aucune configuration de pr√©traitement disponible")

        with col_summary2:
            st.subheader("ü§ñ Mod√®le")
            if hasattr(STATE, 'model_config') and STATE.model_config:
                st.json(STATE.model_config)
            else:
                st.info("Aucune configuration de mod√®le disponible")
            
            st.subheader("‚öôÔ∏è Entra√Ænement")
            if hasattr(STATE, 'training_config') and STATE.training_config:
                st.json(STATE.training_config)
            else:
                st.info("Aucune configuration d'entra√Ænement disponible")
        
        st.markdown("---")
        st.subheader("üîç Validation de la Configuration")
        
        errors, warnings = self.validate_training_configuration()
        
        if errors:
            for error in errors:
                st.error(error)
        else:
            if warnings:
                for warning in warnings:
                    st.warning(warning)
            st.success("‚úÖ Configuration valide - Pr√™t pour l'entra√Ænement!")
        
        # Informations de lancement
        st.markdown("---")
        st.subheader("üéØ Informations de Lancement")

        col_launch1, col_launch2, col_launch3 = st.columns(3)

        with col_launch1:
            total_train_images = 0
            if STATE.loaded and hasattr(STATE.data, 'X_train') and STATE.data.X_train is not None:
                total_train_images = len(STATE.data.X_train)
                
                if (hasattr(STATE, 'preprocessing_config') and 
                    STATE.preprocessing_config and 
                    STATE.preprocessing_config.get("augmentation_enabled", False)):
                    augmentation_factor = STATE.preprocessing_config.get("augmentation_factor", 1)
                    total_train_images *= augmentation_factor
            
            st.metric("üì∑ Images Train", f"{total_train_images:,}")

        with col_launch2:
            epochs = STATE.training_config.get('epochs', 50) if isinstance(STATE.training_config, dict) else getattr(STATE.training_config, 'epochs', 50)
            batch_size = STATE.training_config.get('batch_size', 32) if isinstance(STATE.training_config, dict) else getattr(STATE.training_config, 'batch_size', 32)
            
            estimated_minutes = 1
            if batch_size > 0 and total_train_images > 0:
                images_per_minute = 1200 if torch.cuda.is_available() else 200
                estimated_minutes = max(1, int((total_train_images * epochs) / (batch_size * images_per_minute)))
                
            st.metric("‚è±Ô∏è Temps estim√©", f"{estimated_minutes} min")

        with col_launch3:
            use_weights = STATE.imbalance_config.get("use_class_weights", False) if hasattr(STATE, 'imbalance_config') and STATE.imbalance_config else False
            st.metric("‚öñÔ∏è Poids de classe", "Activ√©s" if use_weights else "D√©sactiv√©s")

        # Informations syst√®me
        st.markdown("---")
        st.subheader("üíª Informations Syst√®me")

        col_sys1, col_sys2, col_sys3 = st.columns(3)

        with col_sys1:
            device = "CUDA üöÄ" if torch.cuda.is_available() else "CPU ‚ö°"
            st.info(f"**Device:** {device}")
            if torch.cuda.is_available():
                try:
                    gpu_name = torch.cuda.get_device_name(0)
                    gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)
                    st.success(f"**GPU:** {gpu_name} ({gpu_memory:.1f} GB)")
                except Exception:
                    st.warning("**GPU:** Informations non disponibles")

        with col_sys2:
            mixed_precision = STATE.training_config.get('use_mixed_precision', False) if isinstance(STATE.training_config, dict) else getattr(STATE.training_config, 'use_mixed_precision', False)
            st.info(f"**Mixed Precision:** {'Activ√©e üöÄ' if mixed_precision else 'D√©sactiv√©e'}")

        with col_sys3:
            deterministic = STATE.training_config.get('deterministic', True) if isinstance(STATE.training_config, dict) else getattr(STATE.training_config, 'deterministic', True)
            st.info(f"**Mode D√©terministe:** {'Activ√© ‚úÖ' if deterministic else 'D√©sactiv√©'}")

        st.markdown("---")

        # Bouton de lancement
        launch_disabled = len(errors) > 0 if 'errors' in locals() else True
        
        if st.button(
            "üöÄ D√©marrer l'Entra√Ænement", 
            type="primary", 
            use_container_width=True, 
            disabled=launch_disabled
        ):
            self.launch_training()

        # Navigation
        st.markdown("---")
        col_back, _ = st.columns(2)
        with col_back:
            if st.button("‚¨ÖÔ∏è Retour", use_container_width=True):
                STATE.current_step = 4
                st.rerun()

        st.markdown('</div>', unsafe_allow_html=True)
    
    def validate_training_configuration(self):
        """Valide la configuration compl√®te avant lancement"""
        errors = []
        warnings = []
        
        # V√©rification des donn√©es
        required_data_attrs = ['X_train', 'y_train', 'X_val', 'y_val', 'X_test', 'y_test']
        
        for attr in required_data_attrs:
            if not hasattr(STATE.data, attr):
                errors.append(f"‚ùå Attribut manquant dans STATE.data: {attr}")
            elif getattr(STATE.data, attr, None) is None:
                errors.append(f"‚ùå Donn√©es manquantes: {attr} est None")
        
        # V√©rification des configurations essentielles
        if not hasattr(STATE, 'model_config') or not STATE.model_config:
            errors.append("‚ùå Configuration du mod√®le manquante ou vide")
        
        if not hasattr(STATE, 'training_config') or not STATE.training_config:
            errors.append("‚ùå Configuration d'entra√Ænement manquante ou vide")
        
        # V√©rifications des hyperparam√®tres
        if hasattr(STATE, 'training_config') and STATE.training_config:
            if isinstance(STATE.training_config, dict):
                epochs = STATE.training_config.get('epochs', 50)
                batch_size = STATE.training_config.get('batch_size', 32)
            else:
                epochs = getattr(STATE.training_config, 'epochs', 50)
                batch_size = getattr(STATE.training_config, 'batch_size', 32)
            
            if epochs > 100:
                warnings.append("‚ö†Ô∏è Nombre d'√©poques √©lev√© (>100)")
            
            if batch_size > 64 and not torch.cuda.is_available():
                warnings.append("‚ö†Ô∏è Batch size √©lev√© (>64) sans GPU")
        
        return errors, warnings

    def launch_training(self):
        """Lance l'entra√Ænement avec la configuration compl√®te"""
        training_container = st.container()
        with training_container:
            st.markdown("### üìà Entra√Ænement en Cours...")
            
            # Initialisation des composants d'interface
            progress_bar = st.progress(0)
            status_text = st.empty()
            metrics_placeholder = st.empty()
            results_placeholder = st.empty()
            
            try:
                # Configuration des callbacks
                streamlit_components = {
                    "progress_bar": progress_bar,
                    "status_text": status_text,
                    "metrics_placeholder": metrics_placeholder
                }
                
                # D√©termination du type d'anomalie
                model_type = STATE.model_config["model_type"]
                anomaly_type = None
                if model_type in ["conv_autoencoder", "variational_autoencoder", "denoising_autoencoder", "patch_core"]:
                    anomaly_type = "structural"
                
                # Passer split_config au contexte
                context_metadata = {
                    "dataset_name": getattr(STATE.data, 'name', 'unknown'),
                    "user_id": "anonymous"
                }
                
                # Ajout split_config si disponible
                if hasattr(STATE.data, 'split_config') and STATE.data.split_config:
                    context_metadata['split_config'] = STATE.data.split_config
                    logger.info(f"‚úÖ split_config ajout√© au contexte: {STATE.data.split_config}")
                else:
                    logger.warning("‚ö†Ô∏è split_config absent, mode sera d√©duit d'anomaly_type")
                
                # Lancement de l'entra√Ænement
                model, history = self.train_with_metier_logic(
                    streamlit_components, 
                    anomaly_type,
                    context_metadata  # Passage metadata enrichi
                )
                # Gestion des r√©sultats
                if model is not None and history and history.get("success", True):
                    self.handle_training_success(model, history, results_placeholder)
                else:
                    self.handle_training_failure(history, results_placeholder)
                
            except Exception as e:
                self.handle_training_error(e, results_placeholder)

    def train_with_metier_logic(self, streamlit_components, anomaly_type, context_metadata):
        """Interface vers l'orchestrateur d'entra√Ænement"""
        try:
            # Cr√©ation du contexte d'entra√Ænement
            context = TrainingContext(
                X_train=STATE.data.X_train,
                y_train=STATE.data.y_train,
                X_val=STATE.data.X_val, 
                y_val=STATE.data.y_val,
                model_config=STATE.model_config,
                training_config=STATE.training_config,
                preprocessing_config=STATE.preprocessing_config,
                callbacks=self._create_callbacks(streamlit_components),
                anomaly_type=anomaly_type,
                metadata=context_metadata 
            )
            
            # Ajouter split_config directement au contexte
            if 'split_config' in context_metadata:
                context.split_config = context_metadata['split_config']
                logger.info("‚úÖ split_config propag√© au TrainingContext")
            
            # D√©l√©gation √† l'orchestrateur
            result = training_orchestrator.train(context)
            
            if result.success:
                STATE.preprocessor = result.preprocessor
                return result.model, result.history
            else:
                return None, {'success': False, 'error': result.error}
                
        except Exception as e:
            logger.error(f"Erreur interface training: {e}", exc_info=True)
            return None, {'success': False, 'error': str(e)}

    def _create_callbacks(self, streamlit_components):
        """Cr√©e les callbacks Streamlit"""
        callbacks = []
        
        if streamlit_components:
            callbacks.append(StreamlitCallback(
                progress_bar=streamlit_components.get('progress_bar'),
                status_text=streamlit_components.get('status_text'),
                total_epochs=STATE.training_config.get('epochs', 50) if isinstance(STATE.training_config, dict) else getattr(STATE.training_config, 'epochs', 50)
            ))
        
        callbacks.append(LoggingCallback(log_every_n_epochs=5))
        
        return callbacks
    
    def handle_training_success(self, model, history, results_placeholder):
        """G√®re le succ√®s de l'entra√Ænement"""
        # Sauvegarde dans STATE
        STATE.trained_model = model
        STATE.training_history = history
        
        preprocessor = getattr(STATE, 'preprocessor', None)
        
        STATE.training_results = {
            "model": model,
            "history": history,
            "training_config": getattr(STATE, 'training_config', {}),
            "model_config": getattr(STATE, 'model_config', {}),
            "preprocessing_config": getattr(STATE, 'preprocessing_config', {}),
            "imbalance_config": getattr(STATE, 'imbalance_config', {}),
            "preprocessor": preprocessor,
            "trained_at": time.strftime("%Y-%m-%d %H:%M:%S")
        }
        
        logger.info("‚úÖ Training completed successfully")
        
        with results_placeholder.container():
            st.success("‚úÖ Entra√Ænement termin√© avec succ√®s!")
            
            # Debug optionnel
            if st.checkbox("üîç Afficher debug", value=False, key="show_debug"):
                with st.expander("üìã Informations Techniques"):
                    st.write("**Preprocessor:**", preprocessor is not None)
                    st.write("**Input Shape:**", history.get('input_shape', 'N/A'))
            
            self.display_training_results(history)
            
    def handle_training_failure(self, history, results_placeholder):
        """G√®re l'√©chec de l'entra√Ænement"""
        with results_placeholder.container():
            st.error("‚ùå L'entra√Ænement a √©chou√©")
            if "error" in history:
                st.error(f"Erreur: {history['error']}")
            
            with st.expander("üîç D√©tails de l'erreur"):
                st.json(history)
            
            if st.button("üîô Retour √† la configuration", use_container_width=True):
                STATE.current_step = 4
                st.rerun()
    
    def handle_training_error(self, error, results_placeholder):
        """G√®re les erreurs pendant l'entra√Ænement"""
        with results_placeholder.container():
            st.error(f"‚ùå Erreur lors de l'entra√Ænement: {str(error)}")
            self.logger.error(f"Training error: {error}", exc_info=True)
            
            with st.expander("üîç Stack trace compl√®te"):
                import traceback
                st.code(traceback.format_exc())
    
    def display_training_results(self, history):
        """Affiche les r√©sultats d√©taill√©s de l'entra√Ænement"""
        # M√©triques principales
        col_result1, col_result2, col_result3, col_result4 = st.columns(4)
        
        with col_result1:
            st.metric("Meilleure Loss Val", f"{history.get('best_val_loss', 0):.4f}")
        
        with col_result2:
            st.metric("√âpoques Effectu√©es", history.get('total_epochs_trained', 0))
        
        with col_result3:
            st.metric("Temps Total", f"{history.get('training_time', 0):.1f}s")
        
        with col_result4:
            early_stopped = "‚úÖ Oui" if history.get('early_stopping_triggered', False) else "‚ùå Non"
            st.metric("Early Stopping", early_stopped)
        
        # Graphiques des courbes d'entra√Ænement
        st.markdown("### üìä Courbes d'Entra√Ænement")
        
        if history.get('train_loss') and history.get('val_loss'):
            fig = go.Figure()
            fig.add_trace(go.Scatter(
                y=history['train_loss'],
                mode='lines',
                name='Train Loss',
                line=dict(color='#667eea', width=2)
            ))
            fig.add_trace(go.Scatter(
                y=history['val_loss'],
                mode='lines',
                name='Val Loss',
                line=dict(color='#764ba2', width=2)
            ))
            fig.update_layout(
                title="Loss au fil des √âpoques",
                xaxis_title="√âpoque",
                yaxis_title="Loss",
                template="plotly_white",
                height=400
            )
            st.plotly_chart(fig, use_container_width=True)
        
        # Actions post-entra√Ænement
        st.markdown("---")
        col_action1, col_action2 = st.columns(2)
        
        with col_action1:
            if st.button("üìä Aller √† l'√âvaluation", type="primary", use_container_width=True):
                st.switch_page("pages/5_anomaly_evaluation.py")
        
        with col_action2:
            if st.button("üîÑ Nouvel Entra√Ænement", use_container_width=True):
                # R√©initialisation partielle
                STATE.current_step = 0
                STATE.workflow_complete = False
                STATE.trained_model = None
                STATE.training_results = None
                st.rerun()
    
    def main(self):
        """Point d'entr√©e principal"""
        self.render_header()
        self.render_workflow_progress()
        
        # Routage des √©tapes
        if STATE.current_step == 0:
            self.render_data_analysis_step()
        elif STATE.current_step == 1:
            self.render_imbalance_analysis_step()
        elif STATE.current_step == 2:
            self.render_preprocessing_step()
        elif STATE.current_step == 3:
            self.render_model_selection_step()
        elif STATE.current_step == 4:
            self.render_training_config_step()
        elif STATE.current_step == 5:
            self.render_training_launch_step()
        
        # Footer
        self.render_footer()
    
    def render_footer(self):
        """Affiche le footer avec des informations utiles"""
        st.markdown("---")
        
        with st.expander("‚ÑπÔ∏è Informations sur la Session"):
            st.markdown("### √âtat de la Configuration")
            
            col_info1, col_info2 = st.columns(2)
            
            with col_info1:
                st.markdown("**Donn√©es:**")
                if STATE.loaded and STATE.data.X is not None:
                    st.write(f"- Images totales: {len(STATE.data.X):,}")
                    st.write(f"- Classes: {len(np.unique(STATE.data.y))}")

                if STATE.loaded and STATE.data.X_train is not None:
                    st.write(f"- Train: {len(STATE.data.X_train):,}")
                    st.write(f"- Validation: {len(STATE.data.X_val):,}")
                    st.write(f"- Test: {len(STATE.data.X_test):,}")
            
            with col_info2:
                st.markdown("**Configuration:**")
                st.write(f"- √âtape actuelle: {STATE.current_step + 1}/6")
                
                if STATE.selected_model_type:
                    st.write(f"- Mod√®le: {STATE.selected_model_type}")
                
                if hasattr(STATE, 'training_config') and STATE.training_config:
                    if isinstance(STATE.training_config, dict):
                        epochs = STATE.training_config.get('epochs', 'N/A')
                        batch_size = STATE.training_config.get('batch_size', 'N/A')
                    else:
                        epochs = getattr(STATE.training_config, 'epochs', 'N/A')
                        batch_size = getattr(STATE.training_config, 'batch_size', 'N/A')
                    st.write(f"- √âpoques: {epochs}")
                    st.write(f"- Batch size: {batch_size}")
        
        # Navigation globale
        st.markdown("---")
        col_nav1, col_nav2, col_nav3 = st.columns(3)
        
        with col_nav1:
            if st.button("üè† Retour au Dashboard", use_container_width=True):
                st.switch_page("pages/1_dashboard.py")
        
        with col_nav2:
            if st.button("üîÑ R√©initialiser le Workflow", use_container_width=True):
                # R√©initialisation compl√®te
                STATE.current_step = 0
                STATE.selected_model_type = None
                STATE.model_config = None
                STATE.training_config = None
                st.rerun()
        
        with col_nav3:
            if hasattr(STATE, 'trained_model') and STATE.trained_model is not None:
                if st.button("üìä √âvaluation des R√©sultats", type="primary", use_container_width=True):
                    st.switch_page("pages/5_anomaly_evaluation.py")


# Lancement de l'application
if __name__ == "__main__":
    app = MLTrainingWorkflowPro()
    app.main()