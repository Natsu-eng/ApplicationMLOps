"""
DataLab Pro - State Manager Global avec MLflow int√©gr√©
Gestion centralis√©e de l'√©tat de l'application Streamlit.
"""

import os
import time
import threading
from typing import Any, Dict, Optional, Set, Tuple, List
from contextlib import contextmanager
from dataclasses import dataclass, field
from enum import Enum
import streamlit as st
import numpy as np
import pandas as pd

from monitoring.mlflow_collector import get_mlflow_collector

# Import du syst√®me de logging centralis√©
from src.shared.logging import get_logger
from utils.task_detector import TaskType

# ========================
# LOGGER
# ========================
logger = get_logger(__name__)

# ========================
# ENUMS
# ========================
class DataType(Enum):
    """Types de donn√©es support√©s"""
    NONE = "none"
    TABULAR = "tabular"
    IMAGES = "images"

class AppPage(Enum):
    """Pages de l'application"""
    HOME = "main.py"
    DASHBOARD = "pages/1_dashboard.py"
    ML_TRAINING = "pages/2_training.py"
    ML_EVALUATION = "pages/3_evaluation.py"
    CV_TRAINING = "pages/4_training_computer.py"
    ANOMALY_EVAL = "pages/5_anomaly_evaluation.py"

class TrainingStep(Enum):
    """√âtapes du workflow ML"""
    DATA_ANALYSIS = 0
    TARGET_SELECTION = 1
    IMBALANCE_ANALYSIS = 2
    PREPROCESSING = 3
    MODEL_SELECTION = 4
    TRAINING_LAUNCH = 5

# ========================
# CONFIG & STATS
# ========================
@dataclass
class Config:
    """Configuration globale de l'application"""
    MAX_FILE_MB: int = 500
    SUPPORTED_EXT: Set[str] = field(default_factory=lambda: {
        '.csv', '.xlsx', '.parquet', '.feather', '.json'
    })
    TIMEOUT_MIN: int = 60
    MAX_MESSAGE_SIZE: int = 500  # MB
    MLFLOW_EXPERIMENT_NAME: str = "datalab_experiments"
    MLFLOW_TRACKING_URI: str = "sqlite:///mlflow.db"

@dataclass
class CalcStats:
    """Statistiques de calcul"""
    total: int = 0
    failed: int = 0
    last: float = 0.0
    avg: float = 0.0
    active: int = 0
    history: list = field(default_factory=list)
    max_hist: int = 100

# ========================
# STATE CLASSES
# ========================
@dataclass
class NavState:
    """√âtat de navigation"""
    current: AppPage = AppPage.HOME
    authorized: Set[AppPage] = field(default_factory=set)
    last_active: float = field(default_factory=time.time)
    current_step: int = 0  # Pour workflow UI

@dataclass
class DataState:
    """√âtat des donn√©es charg√©es"""
    # M√©ta
    loaded: bool = False
    type: DataType = DataType.NONE
    name: Optional[str] = None
    loaded_at: Optional[float] = None

    # Donn√©es tabulaires (ML classique)
    df: Optional[pd.DataFrame] = None
    df_raw: Optional[pd.DataFrame] = None
    feature_list: List[str] = field(default_factory=list)
    target_column: Optional[str] = None
    task_type: Optional[str] = None

    # Donn√©es images (Computer Vision)
    X: Optional[np.ndarray] = None
    X_norm: Optional[np.ndarray] = None
    y: Optional[np.ndarray] = None
    X_train: Optional[np.ndarray] = None
    X_val: Optional[np.ndarray] = None
    X_test: Optional[np.ndarray] = None
    y_train: Optional[np.ndarray] = None
    y_val: Optional[np.ndarray] = None
    y_test: Optional[np.ndarray] = None
    dir: Optional[str] = None
    structure: Optional[dict] = None
    info: Optional[dict] = None
    task: Optional[str] = None
    img_count: Optional[int] = None
    img_shape: Optional[tuple] = None
    n_classes: Optional[int] = None

@dataclass
class TrainingState:
    """
    √âtat de l'entra√Ænement unifi√© (ML classique + Computer Vision)
    üÜï v5.0: Int√©gration MLflow compl√®te
    """
    # === WORKFLOW G√âN√âRAL ===
    current_step: int = 0
    workflow_complete: bool = False
    
    # === CONFIGURATION ML CLASSIQUE ===
    selected_models: List[str] = field(default_factory=list)
    test_size: int = 20
    optimize_hyperparams: bool = False
    
    # === CONFIGURATION COMPUTER VISION ===
    selected_model_type: Optional[str] = None
    model_config: Dict[str, Any] = field(default_factory=dict)
    training_config: Dict[str, Any] = field(default_factory=dict)
    
    # === CONFIGURATION PR√âTRAITEMENT ===
    preprocessing_config: Dict[str, Any] = field(default_factory=lambda: {
        'numeric_imputation': 'mean',
        'categorical_imputation': 'most_frequent',
        'remove_constant_cols': True,
        'remove_identifier_cols': True,
        'scale_features': True,
        'scaling_method': 'standard',
        'encoding_method': 'onehot',
        'pca_preprocessing': False,
        'use_smote': False,
        'smote_k_neighbors': 5
    })
    
    # === CONFIGURATION D√âS√âQUILIBRE ===
    imbalance_config: Dict[str, Any] = field(default_factory=lambda: {
        'imbalance_detected': False,
        'imbalance_ratio': 1.0,
        'use_class_weights': False,
        'use_smote': False,
        'smote_k_neighbors': 5,
        'smote_sampling_strategy': 'auto'
    })
    
    # === EXP√âRIMENTATION ===
    current_experiment: Optional[str] = None
    
    # === R√âSULTATS ===
    training_results: Optional[Any] = None  # MLTrainingResult ou dict
    trained_model: Any = None
    training_history: Optional[Dict[str, Any]] = None
    preprocessor: Any = None
    class_weights: Optional[Dict] = None
    ml_results: Optional[List[Dict]] = None  # Legacy format

    # === üÜï MLFLOW RUNS (CRITIQUE) ===
    mlflow_runs: List[Dict[str, Any]] = field(default_factory=list)
    mlflow_experiment_id: Optional[str] = None
    mlflow_experiment_name: str = "datalab_experiments"
    
    # === M√âTHODES HELPER MLFLOW ===
    def add_mlflow_run(self, run: Dict[str, Any]) -> bool:
        """
        Ajoute un run MLflow avec d√©duplication automatique.
        
        Args:
            run: Dict contenant au minimum 'run_id'
            
        Returns:
            True si ajout√©, False si dupliqu√© ou invalide
        """
        if not isinstance(run, dict):
            logger.warning(f"‚ö†Ô∏è Run invalide (type: {type(run)})")
            return False
        
        run_id = run.get('run_id')
        if not run_id:
            logger.warning("‚ö†Ô∏è Run sans run_id ignor√©")
            return False
        
        # D√©duplication
        existing_ids = {r.get('run_id') for r in self.mlflow_runs if r.get('run_id')}
        
        if run_id in existing_ids:
            logger.debug(f"Run {run_id[:8]} d√©j√† existant")
            return False
        
        self.mlflow_runs.append(run)
        logger.debug(f"‚úÖ Run {run_id[:8]} ajout√© (total: {len(self.mlflow_runs)})")
        return True
    
    def get_mlflow_runs(self, limit: Optional[int] = None) -> List[Dict[str, Any]]:
        """
        R√©cup√®re les runs MLflow avec limite optionnelle.
        
        Args:
            limit: Nombre max de runs √† retourner
            
        Returns:
            Liste de runs
        """
        if limit and limit > 0:
            return self.mlflow_runs[:limit]
        return self.mlflow_runs
    
    def clear_mlflow_runs(self) -> int:
        """
        Nettoie tous les runs MLflow.
        
        Returns:
            Nombre de runs supprim√©s
        """
        count = len(self.mlflow_runs)
        self.mlflow_runs = []
        logger.info(f"üóëÔ∏è {count} runs MLflow supprim√©s")
        return count
    
    def get_mlflow_runs_by_status(self, status: str) -> List[Dict[str, Any]]:
        """
        Filtre runs par statut.
        
        Args:
            status: 'FINISHED', 'RUNNING', 'FAILED', etc.
            
        Returns:
            Liste de runs filtr√©s
        """
        return [r for r in self.mlflow_runs if r.get('status') == status]
    
    def get_mlflow_runs_by_model(self, model_name: str) -> List[Dict[str, Any]]:
        """
        Filtre runs par nom de mod√®le.
        
        Args:
            model_name: Nom du mod√®le
            
        Returns:
            Liste de runs filtr√©s
        """
        return [
            r for r in self.mlflow_runs 
            if r.get('model_name') == model_name or 
               r.get('tags', {}).get('mlflow.runName') == model_name
        ]

@dataclass
class MetricsState:
    """M√©triques syst√®me et application"""
    start: float = field(default_factory=time.time)
    last_active: float = field(default_factory=time.time)
    errors: int = 0
    success: int = 0
    memory_percent: float = 0.0
    calc: CalcStats = field(default_factory=CalcStats)

# ========================
# GLOBAL STATE MANAGER (Singleton Thread-Safe)
# ========================
class StateManager:
    """
    Gestionnaire d'√©tat global de l'application.
    
    Pattern Singleton avec synchronisation thread-safe.
    G√®re navigation, donn√©es, entra√Ænement, m√©triques et MLflow.
    
    üÜï v5.0: Support MLflow complet avec synchronisation multi-niveaux
    """
    
    _instance = None
    _lock = threading.RLock()

    def __new__(cls):
        """Impl√©mentation Singleton thread-safe"""
        with cls._lock:
            if cls._instance is None:
                cls._instance = super().__new__(cls)
                cls._instance._initialized = False
            return cls._instance

    def __init__(self):
        """Initialisation unique du singleton"""
        if not self._initialized:
            self.config = Config()
            self._setup_session()
            
            # üÜï Int√©gration collecteur MLflow
            self.mlflow_collector = get_mlflow_collector()
            
            # Enregistrement callback bidirectionnel
            self.mlflow_collector.register_callback(self._on_mlflow_run_collected)
            
            self._initialized = True
            logger.info("StateManager v1.0 initialis√© avec collecteur MLflow int√©gr√©")


    def _on_mlflow_run_collected(self, run: Dict[str, Any]):
        """
        Callback: synchronise chaque run collect√© vers session_state.
        Appel√© automatiquement par le collecteur MLflow.
        """
        try:
            # Ajout dans training state
            added = st.session_state.training.add_mlflow_run(run)
            
            if added:
                logger.debug(f"Callback: Run {run.get('run_id', 'N/A')[:8]} ‚Üí STATE")
        
        except Exception as e:
            logger.error(f"‚ùå Callback _on_mlflow_run_collected: {e}")


    def _setup_session(self):
        """
        Initialisation s√©curis√©e de tous les √©tats dans session_state.
        Garantit que tous les √©tats existent avec valeurs par d√©faut.
        """
        with self._lock:
            defaults = {
                'nav': NavState(),
                'data': DataState(),
                'training': TrainingState(),
                'metrics': MetricsState(),
                'ready': True,
                'time': time.strftime('%H:%M:%S')
            }
            
            for key, default_value in defaults.items():
                if key not in st.session_state:
                    st.session_state[key] = default_value
                    logger.debug(f"Initialized session_state.{key}")
            
            self._update_auth()

    # ========================================
    # GESTION AUTORISATIONS
    # ========================================
    
    def _update_auth(self):
        """
        Met √† jour les pages autoris√©es selon le type de donn√©es charg√©es.
        
        - Aucune donn√©e: HOME uniquement
        - Donn√©es tabulaires: HOME + DASHBOARD + ML_TRAINING + ML_EVALUATION
        - Donn√©es images: HOME + DASHBOARD + CV_TRAINING + ANOMALY_EVAL
        """
        data_type = st.session_state.data.type
        authorized = {AppPage.HOME}
        
        if data_type == DataType.TABULAR:
            authorized.update({
                AppPage.DASHBOARD,
                AppPage.ML_TRAINING,
                AppPage.ML_EVALUATION
            })
            logger.debug("Auth: Tabular ‚Üí ML pages enabled")
        
        elif data_type == DataType.IMAGES:
            authorized.update({
                AppPage.DASHBOARD,
                AppPage.CV_TRAINING,
                AppPage.ANOMALY_EVAL
            })
            logger.debug("Auth: Images ‚Üí CV pages enabled")
        
        st.session_state.nav.authorized = authorized

    # ========================================
    # NAVIGATION
    # ========================================
    
    def go(self, page: AppPage) -> bool:
        """
        Change la page courante si autoris√©e.
        
        Args:
            page: Page cible (AppPage enum)
            
        Returns:
            True si navigation autoris√©e, False sinon
        """
        if page not in st.session_state.nav.authorized:
            logger.warning(f"‚ö†Ô∏è Acc√®s refus√©: {page.value}")
            st.warning(f"‚ö†Ô∏è Acc√®s refus√© √† {page.name}. Veuillez charger des donn√©es appropri√©es.")
            return False
        
        st.session_state.nav.current = page
        st.session_state.nav.last_active = time.time()
        logger.info(f"‚Üí {page.value}")
        return True

    def switch(self, page: AppPage) -> bool:
        """
        Change de page avec transition Streamlit.
        
        Args:
            page: Page cible
            
        Returns:
            True si succ√®s, False si √©chec
        """
        if not self.go(page):
            return False
        
        try:
            st.switch_page(page.value)
            return True
        except Exception as e:
            logger.error(f"‚ùå switch_page failed: {e}", exc_info=True)
            st.error(f"Erreur de navigation: {e}")
            return False

    # ========================================
    # CHARGEMENT DONN√âES
    # ========================================
    
    def set_tabular(
        self, 
        df: pd.DataFrame, 
        df_raw: Optional[pd.DataFrame], 
        name: str
    ) -> bool:
        """
        Charge des donn√©es tabulaires.
        
        Args:
            df: DataFrame nettoy√©
            df_raw: DataFrame brut original (optionnel)
            name: Nom du fichier/dataset
            
        Returns:
            True si succ√®s, False si √©chec
        """
        try:
            if df is None or df.empty:
                logger.error("‚ùå DataFrame vide ou None")
                return False
            
            # Reset complet avant nouveau chargement
            self.reset_data()
            
            d = st.session_state.data
            d.df = df.copy()
            d.df_raw = df_raw.copy() if df_raw is not None else df.copy()
            d.name = name
            d.type = DataType.TABULAR
            d.loaded = True
            d.loaded_at = time.time()
            
            self._update_auth()
            
            logger.info(f"‚úÖ Tabular loaded: {name} | {df.shape}")
            return True
        
        except Exception as e:
            logger.error(f"‚ùå set_tabular error: {e}", exc_info=True)
            st.error(f"Erreur chargement donn√©es: {e}")
            return False

    def set_images(
        self, 
        X: np.ndarray, 
        X_norm: np.ndarray, 
        y: np.ndarray, 
        dir_path: str, 
        structure: dict, 
        info: dict,
        y_train: Optional[np.ndarray] = None  # ‚úÖ AJOUT
    ) -> bool:
        """
        Charge des donn√©es images avec d√©tection intelligente unsupervised/supervised.
        
        Args:
            y_train: Labels du TRAIN UNIQUEMENT (pour MVTec AD ‚Üí d√©tection unsupervised)
        """
        try:
            if len(X) == 0 or len(X) != len(y):
                logger.error(f"Images invalides: len(X)={len(X)}, len(y)={len(y)}")
                return False
            
            # Reset avant chargement
            self.reset_data()
            
            d = st.session_state.data
            d.X = X
            d.X_norm = X_norm
            d.y = y
            d.dir = dir_path
            d.structure = structure
            d.info = info
            d.type = DataType.IMAGES
            d.name = os.path.basename(dir_path)
            d.loaded = True
            d.loaded_at = time.time()
            d.img_count = len(X)
            d.img_shape = X.shape[1:] if len(X.shape) > 3 else X.shape[1:]
            
            d.y_train = y_train
            
            # === D√âTECTION INTELLIGENTE DE LA T√ÇCHE ===
            from utils.task_detector import detect_cv_task
            
            # Si y_train fourni, l'utiliser pour d√©tection
            labels_for_detection = y_train if y_train is not None else y
            
            task_type, task_metadata = detect_cv_task(labels_for_detection)
            
            d.task = task_type.value
            d.n_classes = task_metadata["n_classes"]
            d.task_metadata = task_metadata
            
            self._update_auth()
            
            # Logs d√©taill√©s
            task_name = {
                "unsupervised": "üîç Unsupervised (MVTec AD)",
                "anomaly_detection": "‚ö†Ô∏è Anomaly Supervised",
                "binary_classification": "üéØ Binary Classification",
                "multiclass_classification": "üéØ Multiclass Classification"
            }.get(task_type.value, task_type.value)
            
            logger.info(
                f"‚úÖ Images charg√©es: {len(X)} images | "
                f"T√¢che d√©tect√©e: {task_name} | "
                f"y_train fourni: {y_train is not None} | "
                f"Classes d√©tect√©es: {len(np.unique(labels_for_detection))}"
            )
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå set_images error: {e}", exc_info=True)
            st.error(f"Erreur chargement images: {e}")
            return False

    # ========================================
    # RESET
    # ========================================
    
    def reset_data(self):
        """Reset s√©curis√© des donn√©es et √©tat d'entra√Ænement"""
        with self._lock:
            st.session_state.data = DataState()
            st.session_state.training = TrainingState()
            self._update_auth()
            logger.info("üóëÔ∏è Data + Training reset")

    def reset_all(self):
        """Reset complet de tous les √©tats"""
        with self._lock:
            st.session_state.data = DataState()
            st.session_state.nav = NavState()
            st.session_state.training = TrainingState()
            st.session_state.metrics = MetricsState()
            self._update_auth()
            logger.info("üóëÔ∏è Full reset (all states)")

    # ========================================
    # VALIDATION
    # ========================================
    
    def validate(self) -> Tuple[bool, str]:
        """
        Valide que des donn√©es sont charg√©es et valides.
        
        Returns:
            (is_valid, message)
        """
        d = st.session_state.data
        
        if not d.loaded:
            return False, "Aucune donn√©e charg√©e"
        
        if d.type == DataType.TABULAR:
            if d.df is None or d.df.empty:
                return False, "DataFrame vide"
            return True, f"{len(d.df):,} lignes √ó {len(d.df.columns)} colonnes"
        
        if d.type == DataType.IMAGES:
            if d.X is None or len(d.X) == 0:
                return False, "Aucune image"
            if len(d.X) != len(d.y):
                return False, f"Incoh√©rence X ({len(d.X)}) ‚â† y ({len(d.y)})"
            return True, f"{len(d.X):,} images | {d.n_classes} classes"
        
        return False, "Type de donn√©es inconnu"

    # ========================================
    # M√âTRIQUES & MONITORING
    # ========================================
    
    @contextmanager
    def calc(self, name: str = "operation"):
        """
        Context manager pour tracking des op√©rations.
        
        Usage:
            with STATE.calc("mon_operation"):
                # code...
        
        Args:
            name: Nom de l'op√©ration (pour logs)
        """
        start_time = time.time()
        stats = st.session_state.metrics.calc
        
        with self._lock:
            stats.active += 1
            stats.total += 1
        
        try:
            yield
        
        except Exception as e:
            with self._lock:
                stats.failed += 1
                st.session_state.metrics.errors += 1
            logger.error(f"‚ùå Calc error [{name}]: {e}", exc_info=True)
            raise
        
        finally:
            duration = time.time() - start_time
            
            with self._lock:
                stats.active -= 1
                stats.last = duration
                stats.history.append(duration)
                
                if len(stats.history) > stats.max_hist:
                    stats.history.pop(0)
                
                stats.avg = sum(stats.history) / len(stats.history) if stats.history else 0
                st.session_state.metrics.success += 1

    def touch(self):
        """Met √† jour le timestamp d'activit√©"""
        st.session_state.metrics.last_active = time.time()
        st.session_state.time = time.strftime('%H:%M:%S')

    def get(self, key: str, default: Any = None) -> Any:
        """
        Acc√®s s√©curis√© aux donn√©es de session.
        
        Args:
            key: Cl√© de session_state
            default: Valeur par d√©faut si cl√© absente
            
        Returns:
            Valeur ou default
        """
        return st.session_state.get(key, default)

    # ========================================
    # üÜï M√âTHODES MLFLOW PUBLIQUES
    # ========================================
    
    def add_mlflow_run(self, run: Dict[str, Any]) -> bool:
        """
        Ajoute un run avec collecteur centralis√©.
        D√©l√®gue au collecteur pour coh√©rence globale.
        """
        # D√©l√©gation au collecteur (source unique de v√©rit√©)
        collected = self.mlflow_collector.add_run(run)
        
        if collected:
            # Ajout local (d√©j√† fait par callback mais double s√©curit√©)
            return st.session_state.training.add_mlflow_run(run)
        
        return False
    
    def get_mlflow_runs(self, limit: Optional[int] = None) -> List[Dict[str, Any]]:
        """
        R√©cup√®re runs depuis collecteur (source unique).
        """
        return self.mlflow_collector.get_runs(limit)
    
    def clear_mlflow_runs(self) -> int:
        """
        Nettoie runs partout (collecteur + states).
        """
        # Collecteur
        count_collector = self.mlflow_collector.clear()
        
        # Training state
        count_training = st.session_state.training.clear_mlflow_runs()
        
        # Session state
        if hasattr(st.session_state, 'mlflow_runs'):
            count_session = len(st.session_state.mlflow_runs)
            st.session_state.mlflow_runs = []
        else:
            count_session = 0
        
        logger.info(
            f"üóëÔ∏è MLflow runs nettoy√©s:\n"
            f"   ‚Ä¢ Collecteur: {count_collector}\n"
            f"   ‚Ä¢ Training: {count_training}\n"
            f"   ‚Ä¢ Session: {count_session}"
        )
        
        return count_collector
    
    def sync_mlflow_runs(self, runs: List[Dict[str, Any]]) -> int:
        """
        Synchronise une liste de runs MLflow.
        
        Args:
            runs: Liste de runs √† synchroniser
            
        Returns:
            Nombre de nouveaux runs ajout√©s
        """
        count = 0
        for run in runs:
            if self.add_mlflow_run(run):
                count += 1
        
        if count > 0:
            logger.info(f"‚úÖ {count} nouveaux runs MLflow synchronis√©s")
        
        return count

    # ========================================
    # PROPERTIES (Acc√®s unifi√© et s√©curis√©)
    # ========================================
    
    # --- Navigation ---
    @property
    def page(self) -> AppPage:
        """Page courante"""
        return st.session_state.nav.current
    
    # --- Type de donn√©es ---
    @property
    def dtype(self) -> DataType:
        """Type de donn√©es charg√©es"""
        return st.session_state.data.type
    
    @property
    def loaded(self) -> bool:
        """Donn√©es charg√©es ?"""
        return st.session_state.data.loaded
    
    @property
    def tabular(self) -> bool:
        """Donn√©es tabulaires charg√©es ?"""
        return self.loaded and self.dtype == DataType.TABULAR
    
    @property
    def images(self) -> bool:
        """Images charg√©es ?"""
        return self.loaded and self.dtype == DataType.IMAGES
    
    # --- √âtats ---
    @property
    def data(self) -> DataState:
        """√âtat des donn√©es"""
        return st.session_state.data
    
    @property
    def nav(self) -> NavState:
        """√âtat de navigation"""
        return st.session_state.nav
    
    @property
    def metrics(self) -> MetricsState:
        """M√©triques syst√®me"""
        return st.session_state.metrics
    
    @property
    def training(self) -> TrainingState:
        """√âtat d'entra√Ænement"""
        return st.session_state.training
    
    # --- Workflow ---
    @property
    def current_step(self) -> int:
        """√âtape courante du workflow"""
        return st.session_state.training.current_step
    
    @current_step.setter
    def current_step(self, value: int):
        st.session_state.training.current_step = value
    
    @property
    def workflow_complete(self) -> bool:
        """Workflow termin√© ?"""
        return st.session_state.training.workflow_complete
    
    @workflow_complete.setter
    def workflow_complete(self, value: bool):
        st.session_state.training.workflow_complete = value
    
    # --- Mod√®les ---
    @property
    def selected_models(self) -> List[str]:
        """Mod√®les s√©lectionn√©s (ML classique)"""
        return st.session_state.training.selected_models
    
    @selected_models.setter
    def selected_models(self, value: List[str]):
        st.session_state.training.selected_models = value
    
    @property
    def selected_model_type(self) -> Optional[str]:
        """Type de mod√®le s√©lectionn√© (CV)"""
        return st.session_state.training.selected_model_type
    
    @selected_model_type.setter
    def selected_model_type(self, value: Optional[str]):
        st.session_state.training.selected_model_type = value
    
    # --- Configuration ---
    @property
    def test_size(self) -> int:
        """Taille du jeu de test (%)"""
        return st.session_state.training.test_size
    
    @test_size.setter
    def test_size(self, value: int):
        st.session_state.training.test_size = value
    
    @property
    def optimize_hyperparams(self) -> bool:
        """Optimisation hyperparam√®tres activ√©e ?"""
        return st.session_state.training.optimize_hyperparams
    
    @optimize_hyperparams.setter
    def optimize_hyperparams(self, value: bool):
        st.session_state.training.optimize_hyperparams = value
    
    @property
    def model_config(self) -> Dict[str, Any]:
        """Configuration du mod√®le"""
        return st.session_state.training.model_config
    
    @model_config.setter
    def model_config(self, value: Dict[str, Any]):
        st.session_state.training.model_config = value
    
    @property
    def training_config(self) -> Dict[str, Any]:
        """Configuration d'entra√Ænement"""
        return st.session_state.training.training_config
    
    @training_config.setter
    def training_config(self, value: Dict[str, Any]):
        st.session_state.training.training_config = value
    
    @property
    def preprocessing_config(self) -> Dict[str, Any]:
        """Configuration pr√©traitement"""
        return st.session_state.training.preprocessing_config
    
    @preprocessing_config.setter
    def preprocessing_config(self, value: Dict[str, Any]):
        st.session_state.training.preprocessing_config = value
    
    @property
    def imbalance_config(self) -> Dict[str, Any]:
        """Configuration d√©s√©quilibre"""
        return st.session_state.training.imbalance_config
    
    @imbalance_config.setter
    def imbalance_config(self, value: Dict[str, Any]):
        st.session_state.training.imbalance_config = value
    
    # --- Features & Target ---
    @property
    def feature_list(self) -> List[str]:
        """Liste des features"""
        return st.session_state.data.feature_list
    
    @feature_list.setter
    def feature_list(self, value: List[str]):
        st.session_state.data.feature_list = value
    
    @property
    def target_column(self) -> Optional[str]:
        """Colonne cible"""
        return st.session_state.data.target_column
    
    @target_column.setter
    def target_column(self, value: Optional[str]):
        st.session_state.data.target_column = value
    
    @property
    def task_type(self) -> Optional[str]:
        """Type de t√¢che ML"""
        return st.session_state.data.task_type
    
    @task_type.setter
    def task_type(self, value: Optional[str]):
        st.session_state.data.task_type = value
    
    # --- R√©sultats ---
    @property
    def training_results(self) -> Optional[Any]:
        """R√©sultats d'entra√Ænement (MLTrainingResult)"""
        return st.session_state.training.training_results
    
    @training_results.setter
    def training_results(self, value: Any):
        st.session_state.training.training_results = value
    
    @property
    def trained_model(self) -> Any:
        """Mod√®le entra√Æn√©"""
        return st.session_state.training.trained_model
    
    @trained_model.setter
    def trained_model(self, value: Any):
        st.session_state.training.trained_model = value
    
    @property
    def training_history(self) -> Optional[Dict[str, Any]]:
        """Historique d'entra√Ænement"""
        return st.session_state.training.training_history
    
    @training_history.setter
    def training_history(self, value: Optional[Dict[str, Any]]):
        st.session_state.training.training_history = value
    
    @property
    def preprocessor(self) -> Any:
        """Pr√©processeur"""
        return st.session_state.training.preprocessor
    
    @preprocessor.setter
    def preprocessor(self, value: Any):
        st.session_state.training.preprocessor = value
    
    @property
    def class_weights(self) -> Optional[Dict]:
        """Poids de classes"""
        return st.session_state.training.class_weights
    
    @class_weights.setter
    def class_weights(self, value: Optional[Dict]):
        st.session_state.training.class_weights = value
    
    @property
    def ml_results(self) -> Optional[List[Dict]]:
        """R√©sultats ML (format legacy)"""
        return st.session_state.training.ml_results
    
    @ml_results.setter
    def ml_results(self, value: Optional[List[Dict]]):
        st.session_state.training.ml_results = value
    
    @property
    def current_experiment(self) -> Optional[str]:
        """Nom de l'exp√©rience courante"""
        return st.session_state.training.current_experiment
    
    @current_experiment.setter
    def current_experiment(self, value: Optional[str]):
        st.session_state.training.current_experiment = value
    
    # --- üÜï MLflow (v5.0) ---
    @property
    def mlflow_runs(self) -> List[Dict[str, Any]]:
        """Liste des runs MLflow"""
        return st.session_state.training.mlflow_runs
    
    @mlflow_runs.setter
    def mlflow_runs(self, value: List[Dict[str, Any]]):
        """
        Setter avec validation.
        Pr√©f√©rer add_mlflow_run() pour ajout individuel.
        """
        if not isinstance(value, list):
            logger.warning(f"‚ö†Ô∏è mlflow_runs doit √™tre une liste, re√ßu: {type(value)}")
            value = []
        st.session_state.training.mlflow_runs = value
    
    @property
    def mlflow_experiment_id(self) -> Optional[str]:
        """ID de l'exp√©rience MLflow courante"""
        return st.session_state.training.mlflow_experiment_id
    
    @mlflow_experiment_id.setter
    def mlflow_experiment_id(self, value: Optional[str]):
        st.session_state.training.mlflow_experiment_id = value
    
    @property
    def mlflow_experiment_name(self) -> str:
        """Nom de l'exp√©rience MLflow"""
        return st.session_state.training.mlflow_experiment_name
    
    @mlflow_experiment_name.setter
    def mlflow_experiment_name(self, value: str):
        st.session_state.training.mlflow_experiment_name = value

# ========================
# üÜï FONCTION UTILITAIRE GLOBALE DE SYNCHRONISATION
# ========================

def sync_mlflow_runs_all_sources(mlflow_runs: List[Dict[str, Any]]) -> Dict[str, int]:
    """
    Synchronise les runs MLflow sur TOUTES les sources disponibles.
    
    Cette fonction DOIT √™tre appel√©e apr√®s chaque entra√Ænement pour garantir
    que les runs sont accessibles partout dans l'application.
    
    Args:
        mlflow_runs: Liste de runs MLflow √† synchroniser
        
    Returns:
        Dict avec compteurs par source:
        {
            'session_state': nb_runs_ajout√©s,
            'STATE': nb_runs_ajout√©s,
            'STATE.training': nb_runs_ajout√©s,
            'total_synchronized': total
        }
    
    Usage:
        # Dans orchestrateur ou training.py apr√®s entra√Ænement:
        from monitoring.state_managers import sync_mlflow_runs_all_sources
        
        mlflow_runs = [...]  # runs collect√©s
        sync_mlflow_runs_all_sources(mlflow_runs)
    """
    
    if not mlflow_runs:
        logger.warning("‚ö†Ô∏è Aucun run MLflow √† synchroniser")
        return {
            'session_state': 0,
            'STATE': 0,
            'STATE.training': 0,
            'total_synchronized': 0
        }
    
    logger.info(f"üîÑ Synchronisation de {len(mlflow_runs)} runs MLflow...")
    
    counters = {
        'session_state': 0,
        'STATE': 0,
        'STATE.training': 0,
        'total_synchronized': 0
    }
    
    # === SOURCE 1: st.session_state.mlflow_runs ===
    try:
        if not hasattr(st.session_state, 'mlflow_runs'):
            st.session_state.mlflow_runs = []
        
        existing_ids = {
            r.get('run_id') 
            for r in st.session_state.mlflow_runs 
            if r.get('run_id')
        }
        
        new_runs = [
            r for r in mlflow_runs 
            if r.get('run_id') and r.get('run_id') not in existing_ids
        ]
        
        if new_runs:
            st.session_state.mlflow_runs.extend(new_runs)
            counters['session_state'] = len(new_runs)
            logger.info(
                f"‚úÖ {len(new_runs)} runs ‚Üí session_state.mlflow_runs "
                f"(total: {len(st.session_state.mlflow_runs)})"
            )
    
    except Exception as e:
        logger.error(f"‚ùå Erreur sync session_state: {e}")
    
    # === SOURCE 2: STATE.mlflow_runs (via property) ===
    try:
        # Utilise le StateManager singleton global
        existing_ids = {
            r.get('run_id') 
            for r in STATE.mlflow_runs 
            if r.get('run_id')
        }
        
        new_runs = [
            r for r in mlflow_runs 
            if r.get('run_id') and r.get('run_id') not in existing_ids
        ]
        
        if new_runs:
            # Ajout via m√©thode pour d√©duplication automatique
            for run in new_runs:
                STATE.add_mlflow_run(run)
            
            counters['STATE'] = len(new_runs)
            logger.info(
                f"‚úÖ {len(new_runs)} runs ‚Üí STATE.mlflow_runs "
                f"(total: {len(STATE.mlflow_runs)})"
            )
    
    except Exception as e:
        logger.error(f"‚ùå Erreur sync STATE: {e}")
    
    # === SOURCE 3: STATE.training.mlflow_runs (direct) ===
    try:
        existing_ids = {
            r.get('run_id') 
            for r in st.session_state.training.mlflow_runs 
            if r.get('run_id')
        }
        
        new_runs = [
            r for r in mlflow_runs 
            if r.get('run_id') and r.get('run_id') not in existing_ids
        ]
        
        if new_runs:
            for run in new_runs:
                st.session_state.training.add_mlflow_run(run)
            
            counters['STATE.training'] = len(new_runs)
            logger.info(
                f"‚úÖ {len(new_runs)} runs ‚Üí STATE.training.mlflow_runs "
                f"(total: {len(st.session_state.training.mlflow_runs)})"
            )
    
    except Exception as e:
        logger.error(f"‚ùå Erreur sync STATE.training: {e}")
    
    # === CALCUL TOTAL ===
    counters['total_synchronized'] = sum([
        counters['session_state'],
        counters['STATE'],
        counters['STATE.training']
    ])
    
    if counters['total_synchronized'] > 0:
        logger.info(
            f"‚úÖ Synchronisation MLflow termin√©e: "
            f"{counters['total_synchronized']} runs ajout√©s au total"
        )
    else:
        logger.info("‚ÑπÔ∏è Aucun nouveau run √† synchroniser (tous d√©j√† pr√©sents)")
    
    return counters

# ========================
# INITIALIZER FUNCTION
# ========================

def init() -> StateManager:
    """
    Initialise et retourne le StateManager global.
    
    Cette fonction DOIT √™tre appel√©e au d√©but de chaque page Streamlit.
    
    G√®re:
    - Initialisation singleton
    - V√©rification timeout session
    - Mise √† jour m√©triques syst√®me
    - Touch timestamp
    
    Returns:
        Instance StateManager (singleton)
    
    Usage:
        from monitoring.state_managers import init, STATE
        
        STATE = init()  # en d√©but de page
        
        # Ou utiliser directement STATE global:
        from monitoring.state_managers import STATE
    """
    
    # R√©cup√©ration/cr√©ation singleton
    sm = StateManager()
    now = time.time()

    # V√©rification que 'metrics' existe
    if "metrics" not in st.session_state:
        logger.warning("‚ö†Ô∏è metrics absent ‚Üí r√©initialisation compl√®te")
        sm.reset_all()
    else:
        # V√©rification timeout session
        last_active = st.session_state.metrics.last_active
        timeout_seconds = sm.config.TIMEOUT_MIN * 60
        
        if now - last_active > timeout_seconds:
            logger.warning(
                f"‚è±Ô∏è Session expir√©e "
                f"({(now - last_active) / 60:.1f} min > {sm.config.TIMEOUT_MIN} min) "
                f"‚Üí reset complet"
            )
            sm.reset_all()

    # Touch timestamp
    sm.touch()

    # Mise √† jour m√©triques syst√®me
    try:
        import psutil # type: ignore
        st.session_state.metrics.memory_percent = psutil.virtual_memory().percent
    except ImportError:
        logger.debug("psutil non disponible (m√©triques m√©moire d√©sactiv√©es)")
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Erreur lecture m√©triques syst√®me: {e}")

    return sm

# ========================
# GLOBAL INSTANCE (Singleton)
# ========================

STATE = StateManager()

# ========================
# EXPORTS
# ========================

__all__ = [
    # Classes principales
    'StateManager',
    'DataType',
    'AppPage',
    'TrainingStep',
    
    # √âtats
    'DataState',
    'TrainingState',
    'NavState',
    'MetricsState',
    
    # Instance globale
    'STATE',
    
    # Fonctions utilitaires
    'init',
    'sync_mlflow_runs_all_sources',
]

# ========================
# üÜï HELPERS DEBUGGING (d√©veloppement)
# ========================

def debug_state_info() -> Dict[str, Any]:
    """
    Retourne un snapshot de l'√©tat actuel pour debugging.
    
    Returns:
        Dict avec informations de debug
    """
    try:
        return {
            'loaded': STATE.loaded,
            'data_type': STATE.dtype.value if STATE.dtype else None,
            'data_name': STATE.data.name,
            'current_page': STATE.page.value if STATE.page else None,
            'current_step': STATE.current_step,
            'workflow_complete': STATE.workflow_complete,
            'selected_models': STATE.selected_models,
            'mlflow_runs_count': len(STATE.mlflow_runs),
            'training_results_present': STATE.training_results is not None,
            'session_age_seconds': time.time() - STATE.metrics.start,
            'memory_percent': STATE.metrics.memory_percent,
            'calc_stats': {
                'total': STATE.metrics.calc.total,
                'failed': STATE.metrics.calc.failed,
                'avg_duration': STATE.metrics.calc.avg,
                'active': STATE.metrics.calc.active
            }
        }
    except Exception as e:
        logger.error(f"‚ùå Erreur debug_state_info: {e}")
        return {'error': str(e)}

def validate_mlflow_consistency() -> Dict[str, Any]:
    """
    Valide la coh√©rence des runs MLflow entre les sources.
    
    Returns:
        Dict avec r√©sultat de validation
    """
    try:
        sources = {}
        
        # Session state
        if hasattr(st.session_state, 'mlflow_runs'):
            sources['session_state'] = len(st.session_state.mlflow_runs)
        else:
            sources['session_state'] = 0
        
        # STATE global
        try:
            sources['STATE'] = len(STATE.mlflow_runs)
        except:
            sources['STATE'] = 0
        
        # STATE.training
        try:
            sources['STATE.training'] = len(STATE.training.mlflow_runs)
        except:
            sources['STATE.training'] = 0
        
        # Analyse
        max_count = max(sources.values())
        min_count = min(sources.values())
        
        is_consistent = (max_count == min_count)
        
        return {
            'is_consistent': is_consistent,
            'sources': sources,
            'max_count': max_count,
            'min_count': min_count,
            'recommendation': (
                "‚úÖ Toutes les sources sont synchronis√©es" 
                if is_consistent 
                else f"‚ö†Ô∏è Incoh√©rence d√©tect√©e: appeler sync_mlflow_runs_all_sources()"
            )
        }
    
    except Exception as e:
        logger.error(f"‚ùå Erreur validate_mlflow_consistency: {e}")
        return {'error': str(e)}

# ========================
# üÜï DECORATORS UTILITAIRES
# ========================

def require_data(func):
    """
    D√©corateur: v√©rifie que des donn√©es sont charg√©es.
    
    Usage:
        @require_data
        def ma_fonction():
            # code qui n√©cessite des donn√©es
    """
    def wrapper(*args, **kwargs):
        is_valid, message = STATE.validate()
        if not is_valid:
            st.error(f"‚ùå Donn√©es requises: {message}")
            logger.warning(f"require_data failed: {message}")
            return None
        return func(*args, **kwargs)
    return wrapper

def require_tabular(func):
    """
    D√©corateur: v√©rifie que des donn√©es tabulaires sont charg√©es.
    
    Usage:
        @require_tabular
        def analyse_ml():
            # code ML classique
    """
    def wrapper(*args, **kwargs):
        if not STATE.tabular:
            st.error("‚ùå Cette fonction n√©cessite des donn√©es tabulaires")
            logger.warning("require_tabular failed")
            return None
        return func(*args, **kwargs)
    return wrapper

def require_images(func):
    """
    D√©corateur: v√©rifie que des images sont charg√©es.
    
    Usage:
        @require_images
        def train_cnn():
            # code Computer Vision
    """
    def wrapper(*args, **kwargs):
        if not STATE.images:
            st.error("‚ùå Cette fonction n√©cessite des images")
            logger.warning("require_images failed")
            return None
        return func(*args, **kwargs)
    return wrapper

# ========================
# LOGGING STARTUP
# ========================

logger.info(
    "StateManager v1.0.0 charg√© | "
    f"Features: MLflow multi-sources, Thread-safe, "
    f"Debugging helpers"
)