# üîç ANALYSE COMPL√àTE - COMPUTER VISION
## D√©tection d'Anomalies Industrielle (MVTec AD, Classification, Anomaly Detection)

**Date**: 2024-12-19  
**Expert**: Analyse approfondie du pipeline complet CV  
**Scope**: Chargement ‚Üí Preprocessing ‚Üí Training ‚Üí Evaluation ‚Üí Prediction ‚Üí Localisation

---

## üìã TABLE DES MATI√àRES

1. [D√©tection Automatique du Type de T√¢che](#1-d√©tection-automatique-du-type-de-t√¢che)
2. [Pipeline d'Entra√Ænement](#2-pipeline-dentra√Ænement)
3. [Phase d'√âvaluation (CRITIQUE)](#3-phase-d√©valuation-critique)
4. [D√©tection du Type d'Erreur](#4-d√©tection-du-type-derreur)
5. [Localisation de l'Erreur (Heatmaps)](#5-localisation-de-lerreur-heatmaps)
6. [Erreurs et Incoh√©rences Trouv√©es](#6-erreurs-et-incoh√©rences-trouv√©es)
7. [Correctifs Propos√©s](#7-correctifs-propos√©s)
8. [Recommandations Finales](#8-recommandations-finales)

---

## 1. D√âTECTION AUTOMATIQUE DU TYPE DE T√ÇCHE

### 1.1 Pipeline de D√©tection

**Fichier cl√©**: `utils/task_detector.py`

```python
def detect_cv_task(y: np.ndarray) -> Tuple[TaskType, Dict[str, Any]]:
```

**Logique de d√©tection** (appliqu√©e sur `y_train` UNIQUEMENT):

1. **CAS 1: UNSUPERVISED (MVTec AD)**
   - Condition: `n_classes == 1` (uniquement des images normales)
   - Retour: `TaskType.UNSUPERVISED`
   - **CRITIQUE**: C'est ici que le syst√®me d√©tecte MVTec AD !

2. **CAS 2: ANOMALY_DETECTION (Supervis√©)**
   - Condition: `n_classes == 2` ET `unique_labels == {0, 1}`
   - Retour: `TaskType.ANOMALY_DETECTION`
   - Labels: `0 = normal`, `1 = anomaly`

3. **CAS 3: BINARY_CLASSIFICATION**
   - Condition: `n_classes == 2` mais labels diff√©rents de {0,1}
   - Exemple: {0, 2} ou {1, 3}

4. **CAS 4: MULTICLASS_CLASSIFICATION**
   - Condition: `n_classes > 2`

### 1.2 Chargement MVTec AD

**Fichier cl√©**: `src/explorations/image_exploration_plots.py`

```python
def _load_mvtec_train_labels(data_dir: str) -> np.ndarray:
    """Charge UNIQUEMENT train/good ‚Üí retourne [0, 0, ..., 0]"""
    train_good_path = Path(data_dir) / "train" / "good"
    image_files = _get_image_files(train_good_path)
    return np.zeros(len(image_files), dtype=int)  # ‚Üê TOUJOURS 0
```

**Fichier**: `load_images_flexible()` ligne 388-433

**Processus**:
1. D√©tecte structure MVTec AD via `detect_dataset_structure()`
2. Si `structure_type == "mvtec_ad"`:
   - `X, y_full = _load_mvtec_structure()` ‚Üí charge train/good + test/good + test/anomalies
   - `y_train = _load_mvtec_train_labels()` ‚Üí **UNIQUEMENT train/good (tous 0)**
3. **D√©cision**:
   - `detect_cv_task(y_train)` ‚Üí d√©tecte `UNSUPERVISED` car `n_classes == 1`
   - Mode ‚Üí `"unsupervised"`

### 1.3 Quand le Pipeline Part en "Anomaly Detection"

**Condition**: `y_train` contient uniquement des `0` (images normales)

**Fichiers impliqu√©s**:
- `ui/training_vision.py` ligne 112-236: `detect_training_mode(y)`
- `utils/task_detector.py` ligne 16-60: `detect_cv_task(y)`

**Ordre de priorit√©**:
1. `STATE.data.y_train` (si disponible)
2. Sinon: param√®tre `y` pass√© √† `detect_training_mode()`

### 1.4 Quand le Pipeline Part en "Classification"

**Condition**: `y_train` contient au moins 2 classes diff√©rentes

**Cas sp√©cifiques**:
- `{0, 1}` ‚Üí `ANOMALY_DETECTION` (supervis√©)
- Autres ‚Üí `BINARY_CLASSIFICATION` ou `MULTICLASS_CLASSIFICATION`

### 1.5 ERREURS POTENTIELLES dans la D√©tection

#### ‚ùå **ERREUR CRITIQUE #1**: Labels Mal Charg√©s

**Probl√®me**:
- Si `y_train` est accidentellement charg√© avec train+test (au lieu de train uniquement)
- Le syst√®me pourrait d√©tecter 2 classes alors que c'est du MVTec AD

**Localisation**: `src/explorations/image_exploration_plots.py` ligne 388-433

**Impact**: **CRITIQUE** - Le mod√®le partira en mode "supervised" au lieu de "unsupervised"

#### ‚ö†Ô∏è **ERREUR #2**: Mapping Invers√© Labels

**Probl√®me**:
- Si les labels sont invers√©s (1=normal, 0=anomaly)
- Le syst√®me d√©tectera quand m√™me `ANOMALY_DETECTION` mais avec mapping invers√©

**Localisation**: `utils/task_detector.py` ligne 36

**Impact**: **MOYEN** - Le mod√®le fonctionnera mais avec s√©mantique invers√©e

#### ‚ö†Ô∏è **ERREUR #3**: Shape Incorrect de y_train

**Probl√®me**:
- Si `y_train` a une shape incorrecte (ex: 2D au lieu de 1D)
- `np.unique(y)` pourrait √©chouer ou retourner des valeurs inattendues

**Impact**: **CRITIQUE** - Crash ou mauvaise d√©tection

---

## 2. PIPELINE D'ENTRA√éNEMENT

### 2.1 Flow Complet

```
load_images_flexible() 
  ‚Üí detect_dataset_structure()
  ‚Üí _load_mvtec_structure() ou _load_categorical_folders()
  ‚Üí y_train = _load_mvtec_train_labels() (si MVTec AD)
  
detect_training_mode(y_train)
  ‚Üí detect_cv_task(y_train)
  ‚Üí Retourne mode: "unsupervised" ou "supervised"

ComputerVisionTrainingOrchestrator.train()
  ‚Üí ComputerVisionTrainer.fit() ou AnomalyAwareTrainer.train()
  ‚Üí _setup_preprocessing() (fit sur train uniquement)
  ‚Üí _build_model()
  ‚Üí _training_loop()
```

### 2.2 Dataloader et Preprocessing

**Fichier**: `src/data/computer_vision_preprocessing.py`

#### DataPreprocessor

```python
class DataPreprocessor:
    def fit(self, X: np.ndarray):
        # D√©tecte format automatiquement (channels_first/last)
        # Calcule mean/std sur train UNIQUEMENT
        # GARANTIT: Pas de fuite de donn√©es
        
    def transform(self, X: np.ndarray, output_format="channels_first"):
        # Convertit vers format PyTorch (N, C, H, W)
        # Applique standardisation: (X - mean) / std
```

**Points critiques**:
- ‚úÖ **Pas de fuite**: `fit()` uniquement sur `X_train`
- ‚úÖ **Format coh√©rent**: Auto-d√©tection puis conversion vers `channels_first`
- ‚ö†Ô∏è **Bug potentiel**: Si format d√©tect√© incorrectement ‚Üí erreur shape

#### DataLoaderFactory

```python
def create(X: np.ndarray, y: np.ndarray, batch_size: int):
    # Conversion tensor
    X_tensor = torch.tensor(X, dtype=torch.float32)
    y_tensor = torch.tensor(y, dtype=torch.long)
    # Cr√©ation DataLoader
    return DataLoader(TensorDataset(X_tensor, y_tensor), ...)
```

**Validation**: ‚úÖ V√©rifie coh√©rence des shapes avant cr√©ation

### 2.3 Augmentations et Normalisation

**Fichier**: `src/data/image_augmentation.py`

**Disponible**: Via Albumentations dans `apply_augmentation()`

**Normalisation**:
- `0-1 (MinMax)`: `/255.0`
- `-1-1`: `(image / 127.5) - 1.0`
- `Standard (ImageNet)`: `(image / 255.0 - mean) / std`

**‚ö†Ô∏è ERREUR #4**: Normalisation Pas Toujours Appliqu√©e

**Probl√®me**: Les augmentations sont optionnelles et peuvent √™tre d√©sactiv√©es

**Impact**: **FAIBLE** - Si d√©sactiv√©es, le mod√®le fonctionne quand m√™me

### 2.4 Forward Pass et Calcul des Pertes

**Fichier**: `src/models/computer_vision_training.py`

#### Pour Classification

```python
def _train_epoch(self, train_loader: DataLoader, is_autoencoder: bool = False):
    for batch_idx, (data, target) in enumerate(train_loader):
        output = self.model(data)  # (B, num_classes)
        loss = self.train_criterion(output, target)  # CrossEntropyLoss
```

#### Pour Autoencoder (Unsupervised)

```python
def _train_epoch(self, train_loader: DataLoader, is_autoencoder: bool = True):
    for batch_idx, (data, target) in enumerate(train_loader):
        target = data  # ‚Üê CRITIQUE: target = input pour reconstruction
        output = self.model(data)  # Reconstructed image
        loss = self.train_criterion(output, target)  # MSELoss
```

**‚úÖ COH√âRENT**: La logique distingue bien classification et autoencoder

### 2.5 M√©triques Utilis√©es

#### Classification
- `accuracy_score`
- `precision_score`, `recall_score`, `f1_score`
- `roc_auc_score` (si binaire)
- `confusion_matrix`

#### Autoencoder
- `mean_reconstruction_error`
- `std_reconstruction_error`
- `threshold_95percentile`
- M√©triques de classification bas√©es sur seuil adaptatif

**Fichier**: `src/models/computer_vision_training.py` ligne 935-974

### 2.6 ERREURS dans l'Entra√Ænement

#### ‚ùå **ERREUR CRITIQUE #5**: Incoh√©rence Format Preprocessing

**Probl√®me**:
- Si `X_train` arrive en `channels_last` mais que le preprocessor d√©tecte `channels_first`
- Les statistiques calcul√©es seront fausses

**Localisation**: `src/data/computer_vision_preprocessing.py` ligne 119-143

**Impact**: **CRITIQUE** - Normalisation incorrecte ‚Üí mod√®le ne converge pas

#### ‚ö†Ô∏è **ERREUR #6**: Labels Mal Align√©s

**Probl√®me**:
- Si `y_train` et `X_train` ne sont pas dans le m√™me ordre apr√®s chargement
- Les labels ne correspondent plus aux bonnes images

**Impact**: **CRITIQUE** - Le mod√®le apprend les mauvaises associations

#### ‚ö†Ô∏è **ERREUR #7**: Seuil Adaptatif Trop Restrictif

**Probl√®me**:
- Dans `_predict_autoencoder()` ligne 1096-1098:
  ```python
  threshold = np.percentile(reconstruction_errors, 95)
  ```
- Si le dataset de train contient d√©j√† des anomalies ‚Üí seuil fauss√©

**Impact**: **MOYEN** - Faux positifs ou faux n√©gatifs

---

## 3. PHASE D'√âVALUATION (CRITIQUE)

### 3.1 Comment le Mod√®le D√©cide si une Image est Correcte/D√©fectueuse

#### Pour Autoencoder

**Fichier**: `src/models/computer_vision_training.py` ligne 1068-1109

```python
def _predict_autoencoder(...):
    # 1. Reconstruction
    reconstructed = self.model(data)
    
    # 2. Calcul erreur MSE par image
    errors = torch.mean((data - reconstructed) ** 2, dim=(1, 2, 3))
    
    # 3. Seuil automatique (95√®me percentile)
    threshold = np.percentile(reconstruction_errors, 95)
    
    # 4. Pr√©diction binaire
    predictions = (reconstruction_errors > threshold).astype(int)
```

**Fichier**: `src/app/pages/5_anomaly_evaluation.py` ligne 492-583

**Processus dans `robust_predict_with_preprocessor()`**:

```python
# 1. Normalisation erreurs
max_error = np.max(reconstruction_errors)
y_pred_proba = reconstruction_errors / max_error

# 2. Seuil adaptatif
threshold = np.median(y_pred_proba) + np.std(y_pred_proba)
threshold = np.clip(threshold, 0.3, 0.7)  # Entre 0.3 et 0.7

# 3. Pr√©diction
y_pred_binary = (y_pred_proba > threshold).astype(int)
```

#### Pour Classification

**Fichier**: `src/models/computer_vision_training.py` ligne 1111-1130

```python
def _predict_classifier(...):
    output = self.model(data)
    probs = torch.softmax(output, dim=1)
    preds = output.argmax(dim=1)
```

**Dans `robust_predict_with_preprocessor()`** ligne 589-624:

```python
y_proba = torch.softmax(output, dim=1).cpu().numpy()
if y_proba.shape[1] == 2:
    y_pred_proba = y_proba[:, 1]  # Probabilit√© classe positive
else:
    y_pred_proba = np.max(y_proba, axis=1)  # Multi-classes

y_pred_binary = (y_pred_proba > 0.5).astype(int)
```

### 3.2 Calcul des Scores d'Anomalie

#### Autoencoder

**Score**: Erreur de reconstruction MSE normalis√©e

```python
reconstruction_errors = np.mean((X_processed - reconstructed_np) ** 2, axis=(1, 2, 3))
y_pred_proba = reconstruction_errors / max_error  # Normalisation [0, 1]
```

**‚ö†Ô∏è PROBL√àME**: Si toutes les erreurs sont tr√®s faibles, la normalisation peut cr√©er des faux positifs

#### Classification

**Score**: Probabilit√© de la classe positive (ou max pour multi-classes)

### 3.3 G√©n√©ration des Heatmaps (Localisation)

**Fichier**: `src/evaluation/model_vision_plots.py` ligne 230-294

```python
def plot_anomaly_heatmap(image: np.ndarray, anomaly_score: np.ndarray):
    # image: (H, W, C)
    # anomaly_score: (H, W) ‚Üê Carte spatiale des scores
    
    # Normalisation heatmap
    heatmap = (anomaly_score - anomaly_score.min()) / (anomaly_score.max() - anomaly_score.min() + 1e-8)
    
    # Superposition sur image
    fig.add_trace(go.Image(z=img))
    fig.add_trace(go.Heatmap(z=heatmap, opacity=0.4))
```

**Fichier**: `src/models/computer_vision/anomaly_detection/autoencoders.py` ligne 420-442

```python
def get_reconstruction_error_map(self, x: torch.Tensor) -> torch.Tensor:
    """G√©n√®re une carte spatiale des erreurs de reconstruction"""
    reconstructed = self.forward(x)
    # Erreur par pixel, moyenn√©e sur les canaux
    error_map = torch.mean((x - reconstructed) ** 2, dim=1, keepdim=True)
    return error_map  # (B, 1, H, W)
```

**‚ùå ERREUR CRITIQUE #8**: Heatmap Pas Toujours G√©n√©r√©e

**Probl√®me**:
- La fonction `get_reconstruction_error_map()` existe mais n'est **jamais appel√©e** dans le pipeline d'√©valuation standard
- `plot_anomaly_heatmap()` attend un `anomaly_score` (H, W) mais il n'est pas toujours fourni

**Localisation**:
- `src/evaluation/model_vision_plots.py` ligne 230
- `src/app/pages/5_anomaly_evaluation.py` (aucun appel √† `get_reconstruction_error_map()`)

**Impact**: **CRITIQUE** - Les heatmaps ne sont pas g√©n√©r√©es automatiquement lors de l'√©valuation

### 3.4 Calcul des Masks et Seuils

**‚ùå MANQUANT**: Il n'y a **pas de g√©n√©ration de masks binaires** dans le code

**Ce qui existe**:
- `error_map` spatial dans `get_reconstruction_error_map()`
- `plot_anomaly_heatmap()` pour visualisation

**Ce qui manque**:
- Fonction pour convertir `error_map` ‚Üí mask binaire avec seuil
- Alignement du mask avec l'image originale si resize effectu√©

### 3.5 Coh√©rence Ground Truth vs Pr√©dictions

**Fichier**: `src/evaluation/computer_vision_metrics.py`

**Calcul des m√©triques** ligne 176-233:

```python
def compute_core_metrics(y_true: np.ndarray, y_pred: np.ndarray, y_scores: np.ndarray):
    metrics["accuracy"] = accuracy_score(y_true, y_pred)
    metrics["precision"] = precision_score(y_true, y_pred, average='weighted')
    metrics["recall"] = recall_score(y_true, y_pred, average='weighted')
    metrics["f1_score"] = f1_score(y_true, y_pred, average='weighted')
    
    if len(np.unique(y_true)) > 1:
        metrics["auc_roc"] = roc_auc_score(y_true, y_scores)
```

**‚úÖ COH√âRENT**: Les m√©triques sont bien calcul√©es avec validation

**‚ö†Ô∏è ERREUR #9**: Format y_scores Incoh√©rent

**Probl√®me**:
- Pour autoencoder: `y_scores` = `reconstruction_errors` (1D array)
- Pour classification: `y_scores` = `probabilities` (2D array si multi-classes)
- `roc_auc_score()` peut √©chouer si format incorrect

**Impact**: **MOYEN** - Crash si format non g√©r√©

### 3.6 ERREURS dans la Phase d'√âvaluation

#### ‚ùå **ERREUR CRITIQUE #10**: Mauvais Resize ‚Üí Masque Non Align√©

**Probl√®me**:
- Si l'image est resiz√©e avant pr√©diction (ex: 256x256 ‚Üí 224x224)
- La `error_map` retourn√©e aura la shape de l'image resiz√©e (224x224)
- Si on veut la superposer √† l'image originale (256x256) ‚Üí d√©calage

**Localisation**: `src/data/computer_vision_preprocessing.py` ligne 30-37

**Impact**: **CRITIQUE** - Localisation incorrecte des d√©fauts

#### ‚ùå **ERREUR CRITIQUE #11**: Conversion Tensor ‚Üí Numpy Incoh√©rente

**Probl√®me**:
- Dans `robust_predict_with_preprocessor()` ligne 549:
  ```python
  reconstructed_np = reconstructed.cpu().numpy()
  ```
- Mais `X_processed` peut √™tre dans un format diff√©rent (normalis√© vs non-normalis√©)
- Le calcul `(X_processed - reconstructed_np) ** 2` peut √™tre fauss√©

**Impact**: **CRITIQUE** - Scores d'anomalie incorrects

#### ‚ö†Ô∏è **ERREUR #12**: Seuil d'Anomalie Trop Fixe

**Probl√®me**:
- Le seuil de 95√®me percentile est fixe
- Si le dataset de test a une distribution diff√©rente du train ‚Üí faux positifs

**Impact**: **MOYEN** - Performance d√©grad√©e

---

## 4. D√âTECTION DU TYPE D'ERREUR

### 4.1 Comment le Code Identifie le Type d'Erreur

**Fichier**: `src/models/computer_vision_training.py` ligne 1489-1528

```python
def _detect_anomaly_type_from_state(self, STATE) -> Optional[str]:
    # Strat√©gie 1: Metadata explicite
    if STATE.data.metadata.get('anomaly_type'):
        return anomaly_type
    
    # Strat√©gie 2: Nom du dataset
    name_lower = STATE.data.name.lower()
    if any(kw in name_lower for kw in ['crack', 'corrosion', 'deformation']):
        return "structural"
    if any(kw in name_lower for kw in ['scratch', 'stain', 'color']):
        return "visual"
    if any(kw in name_lower for kw in ['dimension', 'alignment', 'size']):
        return "geometric"
    
    # Strat√©gie 3: Structure MVTec AD
    if STATE.data.structure.get('type') == 'mvtec_ad':
        return "structural"
```

**‚ùå LIMITATION MAJEURE**: Le code ne peut **PAS** identifier le type d'erreur √† partir des pr√©dictions du mod√®le

**Ce qui existe**:
- D√©tection bas√©e sur m√©tadonn√©es/nom du dataset (AVANT entra√Ænement)
- Taxonomie des types d'anomalies (structural, visual, geometric)

**Ce qui manque**:
- Classification multi-classes des types d'erreurs (crack, scratch, hole, contamination)
- Mod√®le capable de diff√©rencier les types d'anomalies

### 4.2 Taxonomie des Anomalies

**Fichier**: `src/models/computer_vision_training.py` ligne 1530-1587

**Cat√©gories**:
- **Structural**: crack, corrosion, deformation
- **Visual**: scratch, stain, discoloration
- **Geometric**: misalignment, dimension errors

**‚ö†Ô∏è ERREUR #13**: Mapping Type d'Erreur ‚Üí Mod√®le Non Impl√©ment√©

**Probl√®me**:
- La taxonomie existe mais elle n'influence que la **configuration** du mod√®le (architecture, hyperparam√®tres)
- Elle ne permet **pas** au mod√®le de **classifier** le type d'erreur d√©tect√©

**Impact**: **MOYEN** - Le syst√®me peut d√©tecter une anomalie mais pas dire si c'est une fissure ou une rayure

### 4.3 V√©rification: Le Mod√®le Peut-il Diff√©rencier les Classes ?

**R√©ponse**: **NON**, pour les autoencoders (unsupervised)

**Pourquoi**:
- Autoencoders apprennent uniquement √† reconstruire des images normales
- Ils d√©tectent des anomalies mais ne peuvent pas les classifier par type

**R√©ponse**: **OUI**, pour les classificateurs (supervised)

**Pourquoi**:
- Si le dataset contient plusieurs classes (normal, crack, scratch, hole)
- Un mod√®le de classification peut apprendre √† diff√©rencier ces classes
- Mais le pipeline actuel ne le fait **pas automatiquement**

**Fichier**: `src/models/computer_vision_training.py` ligne 1111-1130

```python
def _predict_classifier(...):
    # Retourne seulement la classe pr√©dite, pas le type d'erreur
    preds = output.argmax(dim=1)
```

### 4.4 ERREURS dans la D√©tection du Type d'Erreur

#### ‚ùå **ERREUR CRITIQUE #14**: Pas de Classification Multi-Classes des Types

**Probl√®me**:
- Le syst√®me ne peut pas dire "c'est une fissure" ou "c'est une rayure"
- Il peut seulement dire "anomalie d√©tect√©e" ou "normal"

**Impact**: **CRITIQUE** - Fonctionnalit√© demand√©e non impl√©ment√©e

#### ‚ö†Ô∏è **ERREUR #15**: Labels Manquants pour Types d'Erreurs

**Probl√®me**:
- M√™me si on voulait entra√Æner un classificateur multi-classes, les labels de type d'erreur ne sont pas charg√©s depuis MVTec AD

**Impact**: **MOYEN** - Impossible d'entra√Æner un mod√®le de classification de types sans labels

---

## 5. LOCALISATION DE L'ERREUR (HEATMAPS)

### 5.1 Comment la Heatmap est G√©n√©r√©e

**Fichier**: `src/models/computer_vision/anomaly_detection/autoencoders.py` ligne 420-442

```python
def get_reconstruction_error_map(self, x: torch.Tensor) -> torch.Tensor:
    """G√©n√®re une carte spatiale des erreurs de reconstruction"""
    self.eval()
    with torch.no_grad():
        reconstructed = self.forward(x)
        # Erreur par pixel, moyenn√©e sur les canaux
        error_map = torch.mean((x - reconstructed) ** 2, dim=1, keepdim=True)
        return error_map  # (B, 1, H, W)
```

**Processus**:
1. Forward pass ‚Üí reconstruction
2. Calcul MSE pixel par pixel: `(x - reconstructed) ** 2`
3. Moyenne sur les canaux: `dim=1`
4. Retourne carte (B, 1, H, W)

### 5.2 Comment le Mask Final est Produit

**‚ùå MANQUANT**: Il n'y a **pas de g√©n√©ration de mask binaire** dans le code

**Ce qui existe**:
- `error_map` continu (valeurs entre 0 et max_error)
- Visualisation via `plot_anomaly_heatmap()`

**Ce qui devrait exister**:
```python
def generate_binary_mask(error_map: torch.Tensor, threshold: float) -> torch.Tensor:
    """Convertit error_map ‚Üí mask binaire"""
    return (error_map > threshold).float()
```

### 5.3 Comment le Seuil est Appliqu√©

**Fichier**: `src/evaluation/model_vision_plots.py` ligne 256

```python
# Normalisation heatmap
heatmap = (anomaly_score - anomaly_score.min()) / (anomaly_score.max() - anomaly_score.min() + 1e-8)
```

**Probl√®me**: Le seuil n'est **pas appliqu√©** sur la heatmap, seulement pour la pr√©diction binaire

### 5.4 Bugs Potentiels dans la Localisation

#### ‚ùå **ERREUR CRITIQUE #16**: Heatmap Non G√©n√©r√©e Automatiquement

**Probl√®me**:
- `get_reconstruction_error_map()` existe mais n'est **jamais appel√©e** dans `robust_predict_with_preprocessor()`
- Les heatmaps ne sont g√©n√©r√©es que si on les demande explicitement

**Localisation**: `src/app/pages/5_anomaly_evaluation.py` (aucun appel √† `get_reconstruction_error_map()`)

**Impact**: **CRITIQUE** - Localisation non disponible par d√©faut

#### ‚ùå **ERREUR CRITIQUE #17**: Dimensions Non Align√©es

**Probl√®me**:
- Si l'image originale est 256x256 et le mod√®le utilise 224x224
- La `error_map` retourn√©e est 224x224
- Si on la superpose √† l'image originale ‚Üí d√©calage

**Localisation**: `src/data/computer_vision_preprocessing.py` ligne 30-37

**Solution n√©cessaire**: Resize de `error_map` vers la taille originale

#### ‚ö†Ô∏è **ERREUR #18**: Format Channels Non Coh√©rent

**Probl√®me**:
- `get_reconstruction_error_map()` retourne (B, 1, H, W) ‚Üí channels_first
- `plot_anomaly_heatmap()` attend (H, W) ‚Üí channels_last
- Conversion n√©cessaire mais pas toujours faite

**Impact**: **MOYEN** - Crash si format incorrect

### 5.5 Si la Localisation Peut √ätre Erron√©e

**OUI**, plusieurs cas:

1. **Resize non align√©**: Si preprocessing resize l'image, la heatmap ne correspond plus
2. **Padding non g√©r√©**: Si le mod√®le utilise padding, les bords peuvent √™tre fauss√©s
3. **Normalisation perdue**: Si la heatmap est g√©n√©r√©e avant normalisation inverse

---

## 6. ERREURS ET INCOH√âRENCES TROUV√âES

### 6.1 R√©sum√© des Erreurs Critiques

| ID | Erreur | Fichier | Ligne | Impact |
|----|--------|---------|-------|--------|
| #1 | Labels mal charg√©s (train+test au lieu de train seul) | `image_exploration_plots.py` | 388-433 | CRITIQUE |
| #3 | Shape incorrect de y_train | `task_detector.py` | 16-60 | CRITIQUE |
| #5 | Incoh√©rence format preprocessing | `computer_vision_preprocessing.py` | 119-143 | CRITIQUE |
| #8 | Heatmap pas toujours g√©n√©r√©e | `model_vision_plots.py` | 230 | CRITIQUE |
| #10 | Mauvais resize ‚Üí masque non align√© | `computer_vision_preprocessing.py` | 30-37 | CRITIQUE |
| #11 | Conversion tensor ‚Üí numpy incoh√©rente | `5_anomaly_evaluation.py` | 549 | CRITIQUE |
| #14 | Pas de classification multi-classes des types | `computer_vision_training.py` | - | CRITIQUE |
| #16 | Heatmap non g√©n√©r√©e automatiquement | `5_anomaly_evaluation.py` | - | CRITIQUE |
| #17 | Dimensions non align√©es | `computer_vision_preprocessing.py` | 30-37 | CRITIQUE |

### 6.2 Erreurs Moyennes

| ID | Erreur | Fichier | Impact |
|----|--------|---------|--------|
| #2 | Mapping invers√© labels | `task_detector.py` | MOYEN |
| #7 | Seuil adaptatif trop restrictif | `computer_vision_training.py` | MOYEN |
| #9 | Format y_scores incoh√©rent | `computer_vision_metrics.py` | MOYEN |
| #12 | Seuil d'anomalie trop fixe | `5_anomaly_evaluation.py` | MOYEN |
| #15 | Labels manquants pour types d'erreurs | - | MOYEN |
| #18 | Format channels non coh√©rent | `model_vision_plots.py` | MOYEN |

---

## 7. CORRECTIFS PROPOS√âS

### 7.1 Correctif #1: G√©n√©ration Automatique des Heatmaps

**Fichier**: `src/app/pages/5_anomaly_evaluation.py`

**Ajout dans `robust_predict_with_preprocessor()`**:

```python
# Apr√®s reconstruction pour autoencoder
if model_type in ["autoencoder", "conv_autoencoder"]:
    reconstructed = model(X_tensor)
    reconstructed_np = reconstructed.cpu().numpy()
    
    # ‚úÖ NOUVEAU: G√©n√©ration heatmaps
    if hasattr(model, 'get_reconstruction_error_map'):
        error_maps = []
        for i in range(X_tensor.shape[0]):
            single_img = X_tensor[i:i+1]
            error_map = model.get_reconstruction_error_map(single_img)
            # Convertir (1, 1, H, W) ‚Üí (H, W)
            error_map_np = error_map[0, 0].cpu().numpy()
            # Resize vers taille originale si n√©cessaire
            if error_map_np.shape != X_test[i].shape[:2]:
                from scipy.ndimage import zoom
                zoom_factors = (
                    X_test[i].shape[0] / error_map_np.shape[0],
                    X_test[i].shape[1] / error_map_np.shape[1]
                )
                error_map_np = zoom(error_map_np, zoom_factors, order=1)
            error_maps.append(error_map_np)
        
        result["error_maps"] = np.array(error_maps)  # (N, H, W)
```

### 7.2 Correctif #2: G√©n√©ration de Masks Binaires

**Nouveau fichier**: `src/evaluation/localization_utils.py`

```python
def generate_binary_mask(
    error_map: np.ndarray,
    threshold: float,
    method: str = "percentile"
) -> np.ndarray:
    """
    G√©n√®re un mask binaire √† partir d'une carte d'erreur.
    
    Args:
        error_map: Carte d'erreur (H, W) ou (B, H, W)
        threshold: Seuil absolu ou percentile
        method: "percentile" ou "absolute"
    
    Returns:
        Mask binaire (H, W) ou (B, H, W)
    """
    if method == "percentile":
        actual_threshold = np.percentile(error_map, threshold * 100)
    else:
        actual_threshold = threshold
    
    mask = (error_map > actual_threshold).astype(np.uint8)
    return mask
```

### 7.3 Correctif #3: Alignement Dimensions Heatmap

**Fichier**: `src/evaluation/model_vision_plots.py`

**Modification de `plot_anomaly_heatmap()`**:

```python
def plot_anomaly_heatmap(
    image: np.ndarray,
    anomaly_score: np.ndarray,
    original_size: Optional[Tuple[int, int]] = None
) -> Optional[go.Figure]:
    # ‚úÖ NOUVEAU: Resize si n√©cessaire
    if original_size and anomaly_score.shape[:2] != original_size:
        from scipy.ndimage import zoom
        zoom_factors = (
            original_size[0] / anomaly_score.shape[0],
            original_size[1] / anomaly_score.shape[1]
        )
        anomaly_score = zoom(anomaly_score, zoom_factors, order=1)
    
    # Validation shapes
    if image.shape[:2] != anomaly_score.shape[:2]:
        raise ValueError(
            f"Shapes non align√©es: image={image.shape[:2]}, "
            f"anomaly_score={anomaly_score.shape[:2]}"
        )
    
    # ... reste du code
```

### 7.4 Correctif #4: Classification Multi-Classes des Types d'Erreurs

**Nouveau fichier**: `src/models/computer_vision/anomaly_classification.py`

```python
class AnomalyTypeClassifier(nn.Module):
    """
    Classificateur des types d'anomalies.
    Entra√Æn√© en plus de l'autoencoder pour identifier crack/scratch/hole/etc.
    """
    
    def __init__(
        self,
        backbone: nn.Module,  # Autoencoder pr√©-entra√Æn√©
        num_anomaly_types: int = 5  # crack, scratch, hole, contamination, unknown
    ):
        super().__init__()
        self.backbone = backbone
        # Geler l'autoencoder
        for param in self.backbone.parameters():
            param.requires_grad = False
        
        # Classificateur sur l'espace latent
        self.classifier = nn.Sequential(
            nn.Linear(backbone.latent_dim, 256),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(256, num_anomaly_types)
        )
    
    def forward(self, x):
        # Encoder seulement
        encoded = self.backbone.encoder(x)
        # Classification
        anomaly_type_logits = self.classifier(encoded)
        return anomaly_type_logits
```

**Modification du pipeline d'entra√Ænement**:
- Si labels de types d'anomalies disponibles ‚Üí entra√Æner `AnomalyTypeClassifier`
- Sinon ‚Üí mode actuel (d√©tection binaire uniquement)

### 7.5 Correctif #5: Validation Coh√©rence y_train

**Fichier**: `src/explorations/image_exploration_plots.py`

**Modification de `load_images_flexible()`**:

```python
def load_images_flexible(...):
    # ... chargement ...
    
    # ‚úÖ NOUVEAU: Validation y_train
    if structure_type == DatasetType.MVTEC_AD.value:
        y_train = _load_mvtec_train_labels(data_dir)
        
        # Validation: y_train doit contenir uniquement des 0
        unique_labels_train = np.unique(y_train)
        if len(unique_labels_train) > 1 or (len(unique_labels_train) == 1 and unique_labels_train[0] != 0):
            logger.error(
                f"‚ùå ERREUR: y_train contient des labels anormaux: {unique_labels_train}. "
                f"Pour MVTec AD, y_train doit contenir uniquement des 0 (images normales)."
            )
            raise ValueError("y_train invalide pour MVTec AD")
        
        logger.info(f"‚úÖ Validation y_train OK: {len(y_train)} images normales (label 0)")
```

---

## 8. RECOMMANDATIONS FINALES

### 8.1 Am√©liorations Prioritaires

1. **HAUTE PRIORIT√â**: G√©n√©rer automatiquement les heatmaps lors de l'√©valuation
2. **HAUTE PRIORIT√â**: Aligner les dimensions heatmap/image originale
3. **HAUTE PRIORIT√â**: Valider la coh√©rence de y_train pour MVTec AD
4. **MOYENNE PRIORIT√â**: Impl√©menter classification multi-classes des types d'erreurs
5. **MOYENNE PRIORIT√â**: G√©n√©rer des masks binaires avec seuil adaptatif

### 8.2 Am√©lioration du Dataset

- Si vous voulez classifier les types d'erreurs (crack, scratch, hole), il faut des labels de types
- MVTec AD fournit les types d'anomalies dans les noms de dossiers (`test/crack/`, `test/scratch/`, etc.)
- **Recommandation**: Charger ces labels depuis la structure MVTec AD

### 8.3 Am√©lioration du Mod√®le

- Pour la localisation pr√©cise: utiliser PatchCore ou mod√®les avec attention
- Pour la classification des types: ajouter une t√™te de classification sur l'encoder

### 8.4 Am√©lioration du Seuil

- Remplacer le seuil fixe (95√®me percentile) par un seuil adaptatif bas√© sur la distribution de test
- Utiliser F1-maximization ou Youden's J statistic pour trouver le seuil optimal

---

## üìä CONCLUSION

### Points Forts

‚úÖ **D√©tection automatique du type de t√¢che** fonctionne correctement  
‚úÖ **Pipeline d'entra√Ænement** robuste avec gestion des erreurs  
‚úÖ **Preprocessing sans fuite** de donn√©es (fit sur train uniquement)  
‚úÖ **Architecture modulaire** et extensible  

### Points Faibles

‚ùå **Localisation (heatmaps)** pas g√©n√©r√©e automatiquement  
‚ùå **Classification des types d'erreurs** non impl√©ment√©e  
‚ùå **Alignement dimensions** heatmap/image non g√©r√©  
‚ùå **Validation y_train** insuffisante pour MVTec AD  

### Impact Global

**Fonctionnalit√©s op√©rationnelles**: 70%  
- D√©tection d'anomalies: ‚úÖ OK
- Localisation: ‚ö†Ô∏è Partielle (heatmaps non g√©n√©r√©es automatiquement)
- Classification des types: ‚ùå Non disponible

**Risques production**: **MOYEN**
- Faux positifs/n√©gatifs possibles (seuil fixe)
- Localisation peut √™tre erron√©e (dimensions non align√©es)
- Pas de classification fine des types d'erreurs

---

**FIN DU RAPPORT**

